{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: IPO Filings Web Scraping and Data Processing\n",
    "\n",
    "**What's the total sum ($m) of 2023 filings that happenned of Fridays?**\n",
    "\n",
    "Re-use the [Code Snippet 1] example to get the data from web for this endpoint: https://stockanalysis.com/ipos/filings/\n",
    "Convert the 'Filing Date' to datetime(), 'Shares Offered' to float64 (if '-' is encountered, populate with NaNs).\n",
    "Define a new field 'Avg_price' based on the \"Price Range\", which equals to NaN if no price is specified, to the price (if only one number is provided), or to the average of 2 prices (if a range is given).\n",
    "You may be inspired by the function `extract_numbers()` in [Code Snippet 4], or you can write your own function to \"parse\" a string.\n",
    "Define a column \"Shares_offered_value\", which equals to \"Shares Offered\" * \"Avg_price\" (when both columns are defined; otherwise, it's NaN)\n",
    "\n",
    "Find the total sum in $m (millions of USD, closest INTEGER number) for all fillings during 2023, which happened on Fridays (`Date.dt.dayofweek()==4`). You should see 32 records in total, 24 of it is not null.\n",
    "\n",
    "(additional: you can read about [S-1 IPO filing](https://www.dfinsolutions.com/knowledge-hub/thought-leadership/knowledge-resources/what-s-1-ipo-filing) to understand the context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 1,
=======
   "execution_count": null,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 1,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": null,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 1,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": null,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 1,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 1,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 6,
=======
=======
>>>>>>> 4ce4663 (almost add question 2 response)
   "execution_count": 157,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 6,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 4ce4663 (almost add question 2 response)
   "execution_count": 157,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 6,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 157,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 6,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 6,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\4101520280.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\503092549.py:11: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> a1fa175 (Add response to first question)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\4101520280.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\503092549.py:11: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> c20d40f (Add response to first question)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\4101520280.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\503092549.py:11: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> a1fa175 (Add response to first question)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\4101520280.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\4101520280.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "  filings_dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "#make the call to the endpoint\n",
=======
    "import pandas as pd\n",
    "import requests\n",
    "\n",
>>>>>>> a1fa175 (Add response to first question)
=======
    "#make the call to the endpoint\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
    "import pandas as pd\n",
    "import requests\n",
    "\n",
>>>>>>> c20d40f (Add response to first question)
=======
    "#make the call to the endpoint\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
    "import pandas as pd\n",
    "import requests\n",
    "\n",
>>>>>>> a1fa175 (Add response to first question)
=======
    "#make the call to the endpoint\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "#make the call to the endpoint\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "}\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/filings/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "filings_dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 7,
=======
   "execution_count": 158,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 7,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 158,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 7,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 158,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 7,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 7,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 326 entries, 0 to 325\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Filing Date     326 non-null    object\n",
      " 1   Symbol          326 non-null    object\n",
      " 2   Company Name    326 non-null    object\n",
      " 3   Price Range     326 non-null    object\n",
      " 4   Shares Offered  326 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 12.9+ KB\n"
=======
      "RangeIndex: 329 entries, 0 to 328\n",
=======
      "RangeIndex: 326 entries, 0 to 325\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
<<<<<<< HEAD
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Filing Date     326 non-null    object\n",
      " 1   Symbol          326 non-null    object\n",
      " 2   Company Name    326 non-null    object\n",
      " 3   Price Range     326 non-null    object\n",
      " 4   Shares Offered  326 non-null    object\n",
      "dtypes: object(5)\n",
<<<<<<< HEAD
      "memory usage: 13.0+ KB\n"
>>>>>>> a1fa175 (Add response to first question)
=======
      "memory usage: 12.9+ KB\n"
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "RangeIndex: 329 entries, 0 to 328\n",
=======
      "RangeIndex: 326 entries, 0 to 325\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
=======
      "RangeIndex: 326 entries, 0 to 325\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Filing Date     326 non-null    object\n",
      " 1   Symbol          326 non-null    object\n",
      " 2   Company Name    326 non-null    object\n",
      " 3   Price Range     326 non-null    object\n",
      " 4   Shares Offered  326 non-null    object\n",
      "dtypes: object(5)\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "memory usage: 13.0+ KB\n"
>>>>>>> c20d40f (Add response to first question)
=======
      "memory usage: 12.9+ KB\n"
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
      "RangeIndex: 329 entries, 0 to 328\n",
=======
      "RangeIndex: 326 entries, 0 to 325\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Filing Date     326 non-null    object\n",
      " 1   Symbol          326 non-null    object\n",
      " 2   Company Name    326 non-null    object\n",
      " 3   Price Range     326 non-null    object\n",
      " 4   Shares Offered  326 non-null    object\n",
      "dtypes: object(5)\n",
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
<<<<<<< HEAD
      "memory usage: 13.0+ KB\n"
>>>>>>> a1fa175 (Add response to first question)
=======
      "memory usage: 12.9+ KB\n"
>>>>>>> 02abad3 (Done with the questions for the homework2)
<<<<<<< HEAD
=======
=======
      "memory usage: 12.9+ KB\n"
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "# put the result into a dataframe\n",
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# put the result into a dataframe\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# put the result into a dataframe\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# put the result into a dataframe\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "# put the result into a dataframe\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings = filings_dfs[0]\n",
    "filings.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define `Filling Date` to datetime\n",
=======
   "execution_count": 159,
=======
   "execution_count": 57,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# define `Filling Date` to datetime\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
   "execution_count": 159,
=======
   "execution_count": 57,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 57,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# define `Filling Date` to datetime\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# define `Filling Date` to datetime\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define `Filling Date` to datetime\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings['Filing Date'] = pd.to_datetime(filings['Filing Date'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 58,
=======
   "execution_count": 160,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 58,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 160,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 58,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 160,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 58,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 58,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 326 entries, 0 to 325\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Filing Date           326 non-null    datetime64[ns]\n",
      " 1   Symbol                326 non-null    object        \n",
      " 2   Company Name          326 non-null    object        \n",
      " 3   Price Range           326 non-null    object        \n",
      " 4   Shares Offered        253 non-null    float64       \n",
      " 5   Avg_price             259 non-null    float64       \n",
      " 6   Shares_offered_value  250 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(3)\n",
      "memory usage: 18.0+ KB\n"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 329 entries, 0 to 328\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Filing Date     329 non-null    datetime64[ns]\n",
      " 1   Symbol          329 non-null    object        \n",
      " 2   Company Name    329 non-null    object        \n",
      " 3   Price Range     329 non-null    object        \n",
      " 4   Shares Offered  329 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 13.0+ KB\n"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "# check the type\n",
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# check the type\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# check the type\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# check the type\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "# check the type\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define `Shares Offered` as float with some cleaning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m filings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShares Offered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mfilings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShares Offered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# define `Shares Offered` as float with some cleaning\n",
=======
   "execution_count": 161,
=======
   "execution_count": 59,
>>>>>>> 02abad3 (Done with the questions for the homework2)
<<<<<<< HEAD
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define `Shares Offered` as float with some cleaning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m filings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShares Offered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mfilings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShares Offered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# define `Shares Offered` as float with some cleaning\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 161,
=======
   "execution_count": 59,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
=======
   "execution_count": 59,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define `Shares Offered` as float with some cleaning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m filings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShares Offered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mfilings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShares Offered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# define `Shares Offered` as float with some cleaning\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 161,
=======
   "execution_count": 59,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define `Shares Offered` as float with some cleaning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m filings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShares Offered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mfilings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShares Offered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\rcata\\anaconda3\\envs\\stock_zoomcamp\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# define `Shares Offered` as float with some cleaning\n",
>>>>>>> 4ce4663 (almost add question 2 response)
<<<<<<< HEAD
=======
=======
    "# define `Shares Offered` as float with some cleaning\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings['Shares Offered'] = pd.to_numeric(filings['Shares Offered'].str.replace('-', ''), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 60,
=======
   "execution_count": 162,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 60,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 162,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 60,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 162,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 60,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 60,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "filings['Shares Offered'] = pd.to_numeric(filings['Shares Offered'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 61,
=======
   "execution_count": 163,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 61,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 163,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 61,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 163,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 61,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 61,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 326 entries, 0 to 325\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Filing Date           326 non-null    datetime64[ns]\n",
      " 1   Symbol                326 non-null    object        \n",
      " 2   Company Name          326 non-null    object        \n",
      " 3   Price Range           326 non-null    object        \n",
      " 4   Shares Offered        253 non-null    float64       \n",
      " 5   Avg_price             259 non-null    float64       \n",
      " 6   Shares_offered_value  250 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(3)\n",
      "memory usage: 18.0+ KB\n"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 329 entries, 0 to 328\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Filing Date     329 non-null    datetime64[ns]\n",
      " 1   Symbol          329 non-null    object        \n",
      " 2   Company Name    329 non-null    object        \n",
      " 3   Price Range     329 non-null    object        \n",
      " 4   Shares Offered  253 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 13.0+ KB\n"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "# cheking the type of `Shares Offered`\n",
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# cheking the type of `Shares Offered`\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# cheking the type of `Shares Offered`\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# cheking the type of `Shares Offered`\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "# cheking the type of `Shares Offered`\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 62,
=======
   "execution_count": 164,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 62,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 164,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 62,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 164,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 62,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 62,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "array(['-', '$3.00', '$10.00', '$5.00', '$4.00 - $5.00', '$4.00 - $4.50',\n",
       "       '$5.00 - $6.00', '$5.00 - $7.00', '$4.00 - $6.00', '$3.00 - $4.00',\n",
       "       '$4.00', '$4.13', '$10.00 - $14.00', '$3.50 - $4.50',\n",
       "       '$7.00 - $8.00', '$8.00 - $10.00', '$11.25 - $13.75',\n",
       "       '$4.00 - $4.75', '$4.30', '$9.00 - $11.00', '$3.00 - $5.00',\n",
       "       '$4.50 - $5.50', '$5.75 - $6.75', '$8.00 - $9.00', '$5.50',\n",
       "       '$4.35 - $6.35', '$20.00', '$5.00 - $8.00', '$6.00 - $6.50',\n",
       "       '$6.00 - $7.00', '$6.00', '$4.45', '$8.00', '$15.00', '$6.25',\n",
       "       '$4.25 - $6.25', '$5.20 - $7.20', '$4.50 - $6.50', '$4.25',\n",
       "       '$7.00 - $9.00', '$5.75', '$18.00 - $20.00', '$7.00 - $7.50',\n",
       "       '$8.50 - $9.50', '$5.00 - $6.50'], dtype=object)"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      ]
     },
     "execution_count": 62,
=======
<<<<<<< HEAD
=======
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "array(['$10.00', '-', '$5.00', '$4.00 - $5.00', '$4.00 - $4.50',\n",
       "       '$5.00 - $6.00', '$4.00 - $6.00', '$5.00 - $7.00',\n",
       "       '$10.00 - $12.00', '$3.00 - $4.00', '$4.00', '$4.13',\n",
       "       '$10.00 - $14.00', '$3.50 - $4.50', '$7.00 - $8.00',\n",
       "       '$8.00 - $10.00', '$11.25 - $13.75', '$4.00 - $4.75', '$4.30',\n",
       "       '$9.00 - $11.00', '$3.00 - $5.00', '$4.50 - $5.50',\n",
       "       '$5.75 - $6.75', '$8.00 - $9.00', '$5.50', '$4.35 - $6.35',\n",
       "       '$20.00', '$6.00 - $6.50', '$6.00 - $7.00', '$6.00', '$4.45',\n",
       "       '$8.00', '$15.00', '$6.25', '$4.25 - $6.25', '$5.20 - $7.20',\n",
       "       '$4.50 - $6.50', '$4.25', '$7.00 - $9.00', '$5.75',\n",
       "       '$18.00 - $20.00', '$7.00 - $7.50', '$8.50 - $9.50',\n",
       "       '$5.00 - $6.50'], dtype=object)"
      ]
     },
     "execution_count": 164,
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
>>>>>>> a1fa175 (Add response to first question)
=======
      ]
     },
     "execution_count": 62,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
      ]
     },
     "execution_count": 62,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
      ]
     },
     "execution_count": 62,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      ]
     },
     "execution_count": 62,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "# cheking the `Price Range` to do the correct processing\n",
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# cheking the `Price Range` to do the correct processing\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# cheking the `Price Range` to do the correct processing\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> a1fa175 (Add response to first question)
=======
    "# cheking the `Price Range` to do the correct processing\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "# cheking the `Price Range` to do the correct processing\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings['Price Range'].unique()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 63,
=======
   "execution_count": 165,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 63,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 165,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 63,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 165,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 63,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 63,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
=======
      "['10.5', '15.5']\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
      "['10.5', '15.5']\n",
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
      "['10.5', '15.5']\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "Average Price: 13.0\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
=======
    "import re\n",
    "import numpy as np\n",
    "\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
    "import re\n",
    "import numpy as np\n",
    "\n",
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
    "import re\n",
    "import numpy as np\n",
    "\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "def calculate_avg_price(price_range):\n",
    "    # Regular expression pattern to extract numbers from the price range string\n",
    "    pattern = r'\\d+\\.\\d+?'\n",
    "    \n",
    "    # Find all numbers in the price range string\n",
    "    prices = re.findall(pattern, price_range)\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
=======
    "    print(prices)\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
    "    print(prices)\n",
>>>>>>> c20d40f (Add response to first question)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
    "    print(prices)\n",
>>>>>>> a1fa175 (Add response to first question)
=======
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "    # Convert numbers to float and handle cases where only one price is provided or no price is specified\n",
    "    if len(prices) == 0:\n",
    "        return np.nan\n",
    "    elif len(prices) == 1:\n",
    "        return float(prices[0])\n",
    "    else:\n",
    "        # Calculate the average of two prices if a range is given\n",
    "        return (float(prices[0]) + float(prices[1])) / 2\n",
    "\n",
    "# Example usage:\n",
    "price_range = \"10.5 - 15.5\"\n",
    "avg_price = calculate_avg_price(price_range)\n",
    "print(\"Average Price:\", avg_price)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the func to create `Avg_price`\n",
=======
   "execution_count": 166,
=======
   "execution_count": 64,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Apply the func to create `Avg_price`\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 166,
=======
   "execution_count": 64,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# Apply the func to create `Avg_price`\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the func to create `Avg_price`\n",
<<<<<<< HEAD
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
=======
   "execution_count": 166,
=======
   "execution_count": 64,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Apply the func to create `Avg_price`\n",
>>>>>>> 4ce4663 (almost add question 2 response)
<<<<<<< HEAD
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings['Avg_price'] = filings['Price Range'].apply(calculate_avg_price)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `Shares_offered_value` with a lambda function \n",
=======
   "execution_count": 167,
=======
   "execution_count": 65,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Create `Shares_offered_value` with a lambda function \n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
   "execution_count": 167,
=======
   "execution_count": 65,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> c20d40f (Add response to first question)
=======
    "# Create `Shares_offered_value` with a lambda function \n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 167,
=======
   "execution_count": 65,
>>>>>>> 02abad3 (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Create `Shares_offered_value` with a lambda function \n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `Shares_offered_value` with a lambda function \n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "filings['Shares_offered_value'] = filings.apply(lambda row: row['Shares Offered'] * row['Avg_price'] if row['Shares Offered'] != np.nan and row['Avg_price'] != np.nan else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 66,
=======
   "execution_count": 168,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 66,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
   "execution_count": 168,
>>>>>>> c20d40f (Add response to first question)
=======
   "execution_count": 66,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "execution_count": 168,
>>>>>>> a1fa175 (Add response to first question)
=======
   "execution_count": 66,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 66,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "Total sum in millions of USD for filings on Fridays in 2023: 286\n"
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 276\n"
>>>>>>> a1fa175 (Add response to first question)
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 286\n"
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
<<<<<<< HEAD
      "Total sum in millions of USD for filings on Fridays in 2023: 276\n"
>>>>>>> c20d40f (Add response to first question)
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 286\n"
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 276\n"
>>>>>>> a1fa175 (Add response to first question)
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 286\n"
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "Total sum in millions of USD for filings on Fridays in 2023: 286\n"
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "# Combine all DataFrames in filings into a single DataFrame\n",
=======
    "# Combine all DataFrames in ipo_dfs into a single DataFrame\n",
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Combine all DataFrames in filings into a single DataFrame\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
<<<<<<< HEAD
    "# Combine all DataFrames in ipo_dfs into a single DataFrame\n",
>>>>>>> c20d40f (Add response to first question)
=======
    "# Combine all DataFrames in filings into a single DataFrame\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
    "# Combine all DataFrames in ipo_dfs into a single DataFrame\n",
>>>>>>> a1fa175 (Add response to first question)
=======
    "# Combine all DataFrames in filings into a single DataFrame\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
    "# Combine all DataFrames in filings into a single DataFrame\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "combined_df = pd.concat([filings], ignore_index=True)\n",
    "\n",
    "# Filter records for 2023 and Fridays\n",
    "fridays_2023_df = combined_df[(combined_df['Filing Date'].dt.year == 2023) & (combined_df['Filing Date'].dt.dayofweek == 4)]\n",
    "# Calculate the total sum in millions of USD\n",
    "total_sum_millions_usd = fridays_2023_df['Shares_offered_value'].sum()/1e6  # Convert to millions of USD\n",
    "\n",
    "# Round the total sum to the closest integer\n",
    "total_sum_millions_usd_rounded = round(total_sum_millions_usd)\n",
    "\n",
    "print(\"Total sum in millions of USD for filings on Fridays in 2023:\", total_sum_millions_usd_rounded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:  IPOs \"Fixed days hold\" strategy\n",
    "\n",
    "\n",
    "**Find the optimal number of days X (between 1 and 30), where 75% quantile growth is the highest?**\n",
    "\n",
    "\n",
    "Reuse [Code Snippet 1] to retrieve the list of IPOs from 2023 and 2024 (from URLs: https://stockanalysis.com/ipos/2023/ and https://stockanalysis.com/ipos/2024/). \n",
    "Get all OHLCV daily prices for all stocks with an \"IPO date\" before March 1, 2024 (\"< 2024-03-01\") - 184 tickers (without 'RYZB'). Please remove 'RYZB', as it is no longer available on Yahoo Finance. \n",
    "\n",
    "Sometimes you may need to adjust the symbol name (e.g., 'IBAC' on stockanalysis.com -> 'IBACU' on Yahoo Finance) to locate OHLCV prices for all stocks.\n",
    "Some of the tickers like 'DYCQ' and 'LEGT' were on the market less than 30 days (11 and 21 days, respectively). Let's leave them in the dataset; it just means that you couldn't hold them for more days than they were listed.\n",
    "\n",
    "Let's assume you managed to buy a new stock (listed on IPO) on the first day at the [Adj Close] price]. Your strategy is to hold for exactly X full days (where X is between 1 and 30) and sell at the \"Adj. Close\" price in X days (e.g., if X=1, you sell on the next day).\n",
    "Find X, when the 75% quantile growth (among 185 investments) is the highest. \n",
    "\n",
    "HINTs:\n",
    "* You can generate 30 additional columns: growth_future_1d ... growth_future_30d, join that with the table of min_dates (first day when each stock has data on Yahoo Finance), and perform vector operations on the resulting dataset.\n",
    "* You can use the `DataFrame.describe()` function to get mean, min, max, 25-50-75% quantiles.\n",
    "\n",
    "\n",
    "Addtional: \n",
    "* You can also ensure that the mean and 50th percentile (median) investment returns are negative for most X values, implying a wager for a \"lucky\" investor who might be in the top 25%.\n",
    "* What's your recommendation: Do you suggest pursuing this strategy for an optimal X?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "cell_type": "code",
   "execution_count": 18,
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 169,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 18,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 169,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 18,
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
   "cell_type": "code",
   "execution_count": 18,
=======
   "execution_count": 18,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "  ipo_dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "}\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/2023/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "ipo_dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 170,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 19,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 19,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      154 non-null    object\n",
      " 1   Symbol        154 non-null    object\n",
      " 2   Company Name  154 non-null    object\n",
      " 3   IPO Price     154 non-null    object\n",
      " 4   Current       154 non-null    object\n",
      " 5   Return        154 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ipos_2023 = ipo_dfs[0]\n",
    "ipos_2023.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 171,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 20,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 20,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "  ipo_dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://stockanalysis.com/ipos/2024/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "ipo_dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 172,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 21,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 21,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      64 non-null     object\n",
      " 1   Symbol        64 non-null     object\n",
      " 2   Company Name  64 non-null     object\n",
      " 3   IPO Price     64 non-null     object\n",
      " 4   Current       64 non-null     object\n",
      " 5   Return        64 non-null     object\n",
<<<<<<< HEAD
      "dtypes: object(6)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ipos_2024 = ipo_dfs[0]\n",
    "ipos_2024.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
=======
=======
      "RangeIndex: 63 entries, 0 to 62\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      63 non-null     object\n",
      " 1   Symbol        63 non-null     object\n",
      " 2   Company Name  63 non-null     object\n",
      " 3   IPO Price     63 non-null     object\n",
      " 4   Current       63 non-null     object\n",
      " 5   Return        63 non-null     object\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      64 non-null     object\n",
      " 1   Symbol        64 non-null     object\n",
      " 2   Company Name  64 non-null     object\n",
      " 3   IPO Price     64 non-null     object\n",
      " 4   Current       64 non-null     object\n",
      " 5   Return        64 non-null     object\n",
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
      "dtypes: object(6)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ipos_2024 = ipo_dfs[0]\n",
    "ipos_2024.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 174,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 22,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 22,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of stacked IPOs DataFrame:\n",
      "       IPO Date Symbol                   Company Name IPO Price Current  \\\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05   \n",
      "1  Dec 19, 2023   LGCB             Linkage Global Inc     $4.00   $3.02   \n",
      "2  Dec 15, 2023    ZKH              ZKH Group Limited    $15.50  $12.73   \n",
      "3  Dec 15, 2023   BAYA       Bayview Acquisition Corp    $10.00  $10.17   \n",
      "4  Dec 14, 2023   INHD             Inno Holdings Inc.     $4.00   $0.64   \n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
      "\n",
      "    Return  \n",
      "0    0.50%  \n",
      "1  -25.00%  \n",
      "2  -17.87%  \n",
      "3    1.90%  \n",
      "4  -83.93%  \n"
=======
      "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.03   \n",
      "1  Dec 19, 2023   LGCB             Linkage Global Inc     $4.00   $3.14   \n",
      "2  Dec 15, 2023    ZKH              ZKH Group Limited    $15.50  $12.50   \n",
      "3  Dec 15, 2023   BAYA       Bayview Acquisition Corp    $10.00  $10.18   \n",
      "4  Dec 14, 2023   INHD             Inno Holdings Inc.     $4.00   $0.71   \n",
      "\n",
      "    Return  \n",
      "0    0.30%  \n",
      "1  -19.00%  \n",
      "2  -18.71%  \n",
      "3    1.80%  \n",
      "4  -82.25%  \n"
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "\n",
      "    Return  \n",
      "0    0.50%  \n",
      "1  -25.00%  \n",
      "2  -17.87%  \n",
      "3    1.90%  \n",
      "4  -83.93%  \n"
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
    "# Concatenate IPO DataFrames for 2023 and 2024\n",
    "stacked_ipos_df = pd.concat([ipos_2023, ipos_2024], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the concatenated DataFrame\n",
    "print(\"First few rows of stacked IPOs DataFrame:\")\n",
    "print(stacked_ipos_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 175,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 23,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 23,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 27, 2023</td>\n",
       "      <td>IROH</td>\n",
       "      <td>Iron Horse Acquisitions Corp.</td>\n",
       "      <td>$10.00</td>\n",
<<<<<<< HEAD
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
=======
       "      <td>$10.03</td>\n",
       "      <td>0.30%</td>\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IPO Date Symbol                   Company Name IPO Price Current Return\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05  0.50%"
      ]
     },
     "execution_count": 23,
=======
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.03  0.30%"
      ]
     },
     "execution_count": 175,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05  0.50%"
      ]
     },
     "execution_count": 23,
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_ipos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 176,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 24,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 24,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "stacked_ipos_df['IPO Date'] = pd.to_datetime(stacked_ipos_df['IPO Date'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 177,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 25,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 25,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
<<<<<<< HEAD
     "execution_count": 25,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 25,
=======
     "execution_count": 177,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 25,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 25,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem --> not always the columns are filled\n",
    "missing_prices_df = stacked_ipos_df[stacked_ipos_df['IPO Price'].astype(str).str.find('-') >= 0]\n",
    "missing_prices_df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 178,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 26,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 26,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "# it has some missing values --> use defensive errors='coerce' (if don't have time to crack into the data errors)\n",
    "#     : pd.to_numeric() function call, which will convert problematic values to NaN.\n",
    "#     otherwise you'll get a ValueError: Unable to parse string \"-\" at position 9\n",
    "stacked_ipos_df['IPO Price'] = pd.to_numeric(stacked_ipos_df['IPO Price'].str.replace('$', ''), errors='coerce')\n",
    "# not sure why, but need to call it again to transform 'object' to 'float64'\n",
    "stacked_ipos_df['IPO Price'] = pd.to_numeric(stacked_ipos_df['IPO Price'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 179,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 27,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 27,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Current\" column\n",
    "stacked_ipos_df['Current'] = pd.to_numeric(stacked_ipos_df['Current'].str.replace('$', ''), errors='coerce')\n",
    "\n",
    "# Convert 'Return' to numeric format (percentage)\n",
    "stacked_ipos_df['Return'] = pd.to_numeric(stacked_ipos_df['Return'].str.replace('%', ''), errors='coerce') / 100"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 180,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 28,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 28,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   IPO Date      218 non-null    datetime64[ns]\n",
      " 1   Symbol        218 non-null    object        \n",
      " 2   Company Name  218 non-null    object        \n",
      " 3   IPO Price     218 non-null    float64       \n",
      " 4   Current       218 non-null    float64       \n",
      " 5   Return        218 non-null    float64       \n",
=======
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   IPO Date      217 non-null    datetime64[ns]\n",
      " 1   Symbol        217 non-null    object        \n",
      " 2   Company Name  217 non-null    object        \n",
      " 3   IPO Price     217 non-null    float64       \n",
      " 4   Current       217 non-null    float64       \n",
      " 5   Return        216 non-null    float64       \n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   IPO Date      218 non-null    datetime64[ns]\n",
      " 1   Symbol        218 non-null    object        \n",
      " 2   Company Name  218 non-null    object        \n",
      " 3   IPO Price     218 non-null    float64       \n",
      " 4   Current       218 non-null    float64       \n",
      " 5   Return        218 non-null    float64       \n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
      "dtypes: datetime64[ns](1), float64(3), object(2)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Correctly applied transformations with 'defensive' techniques, but now not all are non-null\n",
    "stacked_ipos_df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 181,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 29,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 29,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPO Date        0\n",
       "Symbol          0\n",
       "Company Name    0\n",
       "IPO Price       0\n",
       "Current         0\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "Return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
=======
       "Return          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "Return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of checking NULLs\n",
    "# (you need to understand how vector operations work .isnull() and calls chaining .isnull().sum())\n",
    "stacked_ipos_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 182,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 30,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 30,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>MRX</td>\n",
       "      <td>Marex Group plc</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
=======
       "      IPO Date Symbol     Company Name  IPO Price  Current  Return\n",
       "157 2024-04-25    MRX  Marex Group plc       19.0     19.1     NaN"
      ]
     },
     "execution_count": 182,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do you want to leave the record or not?\n",
    "stacked_ipos_df[stacked_ipos_df.Return.isnull()]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 184,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 31,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 31,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "218"
      ]
     },
     "execution_count": 31,
=======
       "217"
      ]
     },
     "execution_count": 184,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "218"
      ]
     },
     "execution_count": 31,
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_ipos_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 185,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 32,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 32,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = stacked_ipos_df[stacked_ipos_df['IPO Date'] < '2024-03-01']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 189,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 33,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 33,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IROH', 'LGCB', 'ZKH', 'BAYA', 'INHD', 'AFJK', 'GSIW', 'FEBO',\n",
       "       'CLBR', 'ELAB', 'RR', 'DDC', 'SHIM', 'GLAC', 'SGN', 'HG', 'CRGX',\n",
       "       'ANSC', 'AITR', 'GVH', 'LXEO', 'PAPL', 'ATGL', 'MNR', 'WBUY',\n",
<<<<<<< HEAD
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
=======
       "       'NCL', 'BIRK', 'GMM', 'LRHC', 'PMEC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
       "       'MSS', 'ANL', 'SYRA', 'VSME', 'LRE', 'TURB', 'MDBH', 'KVYO',\n",
       "       'CART', 'DTCK', 'RYZB', 'NMRA', 'ARM', 'SPPL', 'NWGL', 'SWIN',\n",
       "       'IVP', 'NNAG', 'SRM', 'SPGC', 'LQR', 'NRXS', 'FTEL', 'MIRA',\n",
       "       'PXDT', 'CTNT', 'HRYU', 'SRFM', 'PRZO', 'HYAC', 'KVAC', 'JNVR',\n",
       "       'ELWS', 'WRNT', 'TSBX', 'ODD', 'APGE', 'NETD', 'SGMT', 'BOWN',\n",
       "       'SXTP', 'PWM', 'VTMX', 'INTS', 'SVV', 'KGS', 'FIHL', 'GENK',\n",
       "       'BUJA', 'BOF', 'AZTR', 'CAVA', 'ESHA', 'ATMU', 'ATS', 'IPXX',\n",
       "       'CWD', 'SGE', 'SLRN', 'ALCY', 'KVUE', 'GODN', 'TRNR', 'AACT',\n",
       "       'JYD', 'USGO', 'UCAR', 'WLGS', 'TPET', 'TCJH', 'GDTC', 'VCIG',\n",
       "       'GDHG', 'ARBB', 'ISPR', 'MGIH', 'MWG', 'HSHP', 'SFWL', 'SYT',\n",
       "       'HKIT', 'CHSN', 'TBMC', 'HLP', 'ZJYL', 'TMTC', 'YGFGF', 'OAKU',\n",
       "       'BANL', 'OMH', 'MGRX', 'FORL', 'ICG', 'IZM', 'AESI', 'AIXI',\n",
       "       'SBXC', 'BMR', 'DIST', 'GXAI', 'MARX', 'BFRG', 'ENLT', 'MLYS',\n",
       "       'PTHR', 'BLAC', 'NXT', 'HSAI', 'LSDI', 'LICN', 'GPCR', 'ASST',\n",
       "       'CETU', 'TXO', 'BREA', 'GNLX', 'QSG', 'CVKD', 'SKWD', 'ISRL',\n",
       "       'MGOL', 'SMXT', 'VHAI', 'DYCQ', 'CHRO', 'UMAC', 'TBBB', 'MGX',\n",
       "       'HLXB', 'TELO', 'KYTX', 'PMNT', 'AHR', 'LEGT', 'ANRO', 'GUTS',\n",
       "       'AS', 'FBLG', 'BTSG', 'AVBP', 'HAO', 'CGON', 'YIBO', 'SUGP', 'JL',\n",
       "       'KSPI', 'JVSA', 'PSBD', 'CCTG', 'SYNX', 'SDHC', 'ROMA'],\n",
       "      dtype=object)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 33,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 33,
=======
     "execution_count": 189,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 33,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 33,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 197,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 34,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 34,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
<<<<<<< HEAD
     "execution_count": 34,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 34,
=======
     "execution_count": 197,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 34,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 34,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'IBACU' in list(filtered_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 192,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 35,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 35,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['Symbol'] != 'RYZB']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 193,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 36,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 36,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
<<<<<<< HEAD
     "execution_count": 36,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 36,
=======
     "execution_count": 193,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 36,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 36,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 194,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 37,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 37,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = filtered_df['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 199,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 38,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 38,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
<<<<<<< HEAD
     "execution_count": 38,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 38,
=======
     "execution_count": 199,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 38,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 38,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'IBACU' in tickers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 202,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 39,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 39,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PTHR']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DYCQ']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['LEGT']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['JVSA']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHLCV data for the first ticker (IROH):\n",
      "             Open   High     Low   Close  Adj Close  Volume\n",
      "Date                                                       \n",
      "2024-02-16  10.05  10.05  10.010  10.010     10.010   16700\n",
      "2024-02-20  10.02  10.02  10.020  10.020     10.020    5200\n",
      "2024-02-21  10.02  10.02  10.015  10.015     10.015   98600\n",
      "2024-02-22  10.02  10.02  10.020  10.020     10.020    5600\n",
      "2024-02-23  10.02  10.02  10.010  10.010     10.010   14800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download OHLCV data for each ticker\n",
    "ohlcvs = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        ohlcvs[ticker] = yf.download(ticker, start='2023-01-01', end='2024-03-01')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download data for ticker {ticker}: {str(e)}\")\n",
    "\n",
    "# Display the first few rows of OHLCV data for the first ticker\n",
    "if ohlcvs:\n",
    "    print(f\"OHLCV data for the first ticker ({tickers[0]}):\")\n",
    "    print(ohlcvs[tickers[0]].head())\n",
    "else:\n",
    "    print(\"No OHLCV data downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no data for ['PTHR', 'DYCQ', 'LEGT', 'JVSA']\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": null,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 40,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 40,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth_df(df:pd.DataFrame, prefix:str)->pd.DataFrame:\n",
    "  for i in [1,3,7,30,90,365]:\n",
    "    df['growth_'+prefix+'_'+str(i)+'d'] = df['Adj Close'] / df['Adj Close'].shift(i)\n",
    "    GROWTH_KEYS = [k for k in df.keys() if k.startswith('growth')]\n",
    "  return df[GROWTH_KEYS]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 204,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 41,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 41,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ticker   Min Date\n",
      "0     IROH 2024-02-16\n",
      "1     LGCB 2023-12-26\n",
      "2      ZKH 2023-12-15\n",
      "3     BAYA 2023-12-29\n",
      "4     INHD 2023-12-14\n",
      "..     ...        ...\n",
      "175   PSBD 2024-01-18\n",
      "176   CCTG 2024-01-18\n",
      "177   SYNX 2024-01-12\n",
      "178   SDHC 2024-01-16\n",
      "179   ROMA 2024-01-09\n",
      "\n",
      "[180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store DataFrames for each ticker\n",
    "min_dates_list = []\n",
    "\n",
    "# Iterate through the DataFrame containing OHLCV data for each stock\n",
    "for ticker, df in ohlcvs.items():\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        # Extract the minimum date for the current ticker\n",
    "        min_date = df.index.min()\n",
    "        # Create a DataFrame for the current ticker and its minimum date\n",
    "        min_date_df = pd.DataFrame({'Ticker': [ticker], 'Min Date': [min_date]})\n",
    "        # Append the DataFrame to the list\n",
    "        min_dates_list.append(min_date_df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "min_dates = pd.concat(min_dates_list, ignore_index=True)\n",
    "\n",
    "# Display the min_dates DataFrame\n",
    "print(min_dates)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 205,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 42,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 42,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of X (number of days to hold the stock): 28\n",
      "Max 75th percentile growth: 0.03914195622091493\n"
     ]
    }
   ],
   "source": [
    "# Define a list to store the growth for each value of X\n",
    "growth_for_X = []\n",
    "\n",
    "# Iterate over each possible value of X (from 1 to 30)\n",
    "for X in range(1, 31):\n",
    "    # Calculate the growth for each investment based on the holding period of X days\n",
    "    growths = []\n",
    "    for ticker, df in ohlcvs.items():\n",
    "        # Calculate the percentage growth from buying on the first day and selling after X days\n",
    "        if len(df) >= X + 1:  # Ensure there are enough data points for X days\n",
    "            buy_price = df.iloc[0]['Adj Close']\n",
    "            sell_price = df.iloc[X]['Adj Close']\n",
    "            growth = (sell_price - buy_price) / buy_price\n",
    "            growths.append(growth)\n",
    "\n",
    "    # Calculate the 75th percentile growth for the current value of X\n",
    "    percentile_75 = np.percentile(growths, 75)\n",
    "    # Store the 75th percentile growth for the current value of X\n",
    "    growth_for_X.append(percentile_75)\n",
    "\n",
    "# Find the value of X that maximizes the 75th percentile growth\n",
    "optimal_X = np.argmax(growth_for_X) + 1  # Add 1 because indexing starts from 0\n",
    "max_growth = max(growth_for_X)\n",
    "\n",
    "print(\"Optimal value of X (number of days to hold the stock):\", optimal_X)\n",
    "print(\"Max 75th percentile growth:\", max_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       growth_future_1d  growth_future_2d  growth_future_3d  growth_future_4d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_5d  growth_future_6d  growth_future_7d  growth_future_8d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
<<<<<<< HEAD
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       growth_future_1d  growth_future_2d  growth_future_3d  growth_future_4d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_5d  growth_future_6d  growth_future_7d  growth_future_8d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    # Calculate growth as before, but multiply by -1 to ensure negative returns\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) * -1 if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> 4ce4663 (almost add question 2 response)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\3740329921.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "  ipo_dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "}\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/2023/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "ipo_dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 170,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 19,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 170,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 19,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      154 non-null    object\n",
      " 1   Symbol        154 non-null    object\n",
      " 2   Company Name  154 non-null    object\n",
      " 3   IPO Price     154 non-null    object\n",
      " 4   Current       154 non-null    object\n",
      " 5   Return        154 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ipos_2023 = ipo_dfs[0]\n",
    "ipos_2023.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 171,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 20,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 171,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 20,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_17740\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_2076\\1522156903.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "  ipo_dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://stockanalysis.com/ipos/2024/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "ipo_dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 172,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 21,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 172,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 21,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      64 non-null     object\n",
      " 1   Symbol        64 non-null     object\n",
      " 2   Company Name  64 non-null     object\n",
      " 3   IPO Price     64 non-null     object\n",
      " 4   Current       64 non-null     object\n",
      " 5   Return        64 non-null     object\n",
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
      "RangeIndex: 63 entries, 0 to 62\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   IPO Date      63 non-null     object\n",
      " 1   Symbol        63 non-null     object\n",
      " 2   Company Name  63 non-null     object\n",
      " 3   IPO Price     63 non-null     object\n",
      " 4   Current       63 non-null     object\n",
      " 5   Return        63 non-null     object\n",
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
=======
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
      " 0   IPO Date      64 non-null     object\n",
      " 1   Symbol        64 non-null     object\n",
      " 2   Company Name  64 non-null     object\n",
      " 3   IPO Price     64 non-null     object\n",
      " 4   Current       64 non-null     object\n",
      " 5   Return        64 non-null     object\n",
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "dtypes: object(6)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ipos_2024 = ipo_dfs[0]\n",
    "ipos_2024.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 174,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 22,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 174,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 22,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of stacked IPOs DataFrame:\n",
      "       IPO Date Symbol                   Company Name IPO Price Current  \\\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05   \n",
      "1  Dec 19, 2023   LGCB             Linkage Global Inc     $4.00   $3.02   \n",
      "2  Dec 15, 2023    ZKH              ZKH Group Limited    $15.50  $12.73   \n",
      "3  Dec 15, 2023   BAYA       Bayview Acquisition Corp    $10.00  $10.17   \n",
      "4  Dec 14, 2023   INHD             Inno Holdings Inc.     $4.00   $0.64   \n",
<<<<<<< HEAD
<<<<<<< HEAD
      "\n",
      "    Return  \n",
      "0    0.50%  \n",
      "1  -25.00%  \n",
      "2  -17.87%  \n",
      "3    1.90%  \n",
      "4  -83.93%  \n"
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
      "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.03   \n",
      "1  Dec 19, 2023   LGCB             Linkage Global Inc     $4.00   $3.14   \n",
      "2  Dec 15, 2023    ZKH              ZKH Group Limited    $15.50  $12.50   \n",
      "3  Dec 15, 2023   BAYA       Bayview Acquisition Corp    $10.00  $10.18   \n",
      "4  Dec 14, 2023   INHD             Inno Holdings Inc.     $4.00   $0.71   \n",
      "\n",
      "    Return  \n",
      "0    0.30%  \n",
      "1  -19.00%  \n",
      "2  -18.71%  \n",
      "3    1.80%  \n",
      "4  -82.25%  \n"
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "\n",
      "    Return  \n",
=======
      "\n",
      "    Return  \n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "0    0.50%  \n",
      "1  -25.00%  \n",
      "2  -17.87%  \n",
      "3    1.90%  \n",
      "4  -83.93%  \n"
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
     ]
    }
   ],
   "source": [
    "# Concatenate IPO DataFrames for 2023 and 2024\n",
    "stacked_ipos_df = pd.concat([ipos_2023, ipos_2024], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the concatenated DataFrame\n",
    "print(\"First few rows of stacked IPOs DataFrame:\")\n",
    "print(stacked_ipos_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 175,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 23,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 175,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 23,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 27, 2023</td>\n",
       "      <td>IROH</td>\n",
       "      <td>Iron Horse Acquisitions Corp.</td>\n",
       "      <td>$10.00</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
=======
       "      <td>$10.03</td>\n",
       "      <td>0.30%</td>\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
       "      <td>$10.03</td>\n",
       "      <td>0.30%</td>\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "      <td>$10.05</td>\n",
       "      <td>0.50%</td>\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IPO Date Symbol                   Company Name IPO Price Current Return\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05  0.50%"
      ]
     },
     "execution_count": 23,
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.03  0.30%"
      ]
     },
     "execution_count": 175,
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05  0.50%"
      ]
     },
     "execution_count": 23,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "0  Dec 27, 2023   IROH  Iron Horse Acquisitions Corp.    $10.00  $10.05  0.50%"
      ]
     },
     "execution_count": 23,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_ipos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 176,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 24,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 176,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 24,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "stacked_ipos_df['IPO Date'] = pd.to_datetime(stacked_ipos_df['IPO Date'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 177,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 25,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 177,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 25,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 25,
=======
     "execution_count": 177,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 25,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 177,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
     "execution_count": 25,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem --> not always the columns are filled\n",
    "missing_prices_df = stacked_ipos_df[stacked_ipos_df['IPO Price'].astype(str).str.find('-') >= 0]\n",
    "missing_prices_df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 178,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 26,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 178,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 26,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# it has some missing values --> use defensive errors='coerce' (if don't have time to crack into the data errors)\n",
    "#     : pd.to_numeric() function call, which will convert problematic values to NaN.\n",
    "#     otherwise you'll get a ValueError: Unable to parse string \"-\" at position 9\n",
    "stacked_ipos_df['IPO Price'] = pd.to_numeric(stacked_ipos_df['IPO Price'].str.replace('$', ''), errors='coerce')\n",
    "# not sure why, but need to call it again to transform 'object' to 'float64'\n",
    "stacked_ipos_df['IPO Price'] = pd.to_numeric(stacked_ipos_df['IPO Price'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 179,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 27,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 179,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 27,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Current\" column\n",
    "stacked_ipos_df['Current'] = pd.to_numeric(stacked_ipos_df['Current'].str.replace('$', ''), errors='coerce')\n",
    "\n",
    "# Convert 'Return' to numeric format (percentage)\n",
    "stacked_ipos_df['Return'] = pd.to_numeric(stacked_ipos_df['Return'].str.replace('%', ''), errors='coerce') / 100"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 180,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 28,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 180,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 28,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   IPO Date      218 non-null    datetime64[ns]\n",
      " 1   Symbol        218 non-null    object        \n",
      " 2   Company Name  218 non-null    object        \n",
      " 3   IPO Price     218 non-null    float64       \n",
      " 4   Current       218 non-null    float64       \n",
      " 5   Return        218 non-null    float64       \n",
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   IPO Date      217 non-null    datetime64[ns]\n",
      " 1   Symbol        217 non-null    object        \n",
      " 2   Company Name  217 non-null    object        \n",
      " 3   IPO Price     217 non-null    float64       \n",
      " 4   Current       217 non-null    float64       \n",
      " 5   Return        216 non-null    float64       \n",
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
=======
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
      " 0   IPO Date      218 non-null    datetime64[ns]\n",
      " 1   Symbol        218 non-null    object        \n",
      " 2   Company Name  218 non-null    object        \n",
      " 3   IPO Price     218 non-null    float64       \n",
      " 4   Current       218 non-null    float64       \n",
      " 5   Return        218 non-null    float64       \n",
<<<<<<< HEAD
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
      "dtypes: datetime64[ns](1), float64(3), object(2)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Correctly applied transformations with 'defensive' techniques, but now not all are non-null\n",
    "stacked_ipos_df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 181,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 29,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 181,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 29,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPO Date        0\n",
       "Symbol          0\n",
       "Company Name    0\n",
       "IPO Price       0\n",
       "Current         0\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "Return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
       "Return          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "Return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "Return          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of checking NULLs\n",
    "# (you need to understand how vector operations work .isnull() and calls chaining .isnull().sum())\n",
    "stacked_ipos_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 182,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 30,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 182,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 30,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>IPO Price</th>\n",
       "      <th>Current</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>MRX</td>\n",
       "      <td>Marex Group plc</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
       "      IPO Date Symbol     Company Name  IPO Price  Current  Return\n",
       "157 2024-04-25    MRX  Marex Group plc       19.0     19.1     NaN"
      ]
     },
     "execution_count": 182,
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "Empty DataFrame\n",
       "Columns: [IPO Date, Symbol, Company Name, IPO Price, Current, Return]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do you want to leave the record or not?\n",
    "stacked_ipos_df[stacked_ipos_df.Return.isnull()]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 184,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 31,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 184,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 31,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "218"
      ]
     },
     "execution_count": 31,
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
       "217"
      ]
     },
     "execution_count": 184,
<<<<<<< HEAD
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "218"
      ]
     },
     "execution_count": 31,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "218"
      ]
     },
     "execution_count": 31,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_ipos_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 185,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 32,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 185,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 32,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = stacked_ipos_df[stacked_ipos_df['IPO Date'] < '2024-03-01']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 189,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 33,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 189,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 33,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IROH', 'LGCB', 'ZKH', 'BAYA', 'INHD', 'AFJK', 'GSIW', 'FEBO',\n",
       "       'CLBR', 'ELAB', 'RR', 'DDC', 'SHIM', 'GLAC', 'SGN', 'HG', 'CRGX',\n",
       "       'ANSC', 'AITR', 'GVH', 'LXEO', 'PAPL', 'ATGL', 'MNR', 'WBUY',\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
=======
       "       'NCL', 'BIRK', 'GMM', 'LRHC', 'PMEC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
       "       'NCL', 'BIRK', 'GMM', 'LRHC', 'PMEC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
       "       'NCL', 'BIRK', 'GMM', 'PMEC', 'LRHC', 'GPAK', 'SPKL', 'QETA',\n",
>>>>>>> 2eed79c (Done with the questions for the homework2)
       "       'MSS', 'ANL', 'SYRA', 'VSME', 'LRE', 'TURB', 'MDBH', 'KVYO',\n",
       "       'CART', 'DTCK', 'RYZB', 'NMRA', 'ARM', 'SPPL', 'NWGL', 'SWIN',\n",
       "       'IVP', 'NNAG', 'SRM', 'SPGC', 'LQR', 'NRXS', 'FTEL', 'MIRA',\n",
       "       'PXDT', 'CTNT', 'HRYU', 'SRFM', 'PRZO', 'HYAC', 'KVAC', 'JNVR',\n",
       "       'ELWS', 'WRNT', 'TSBX', 'ODD', 'APGE', 'NETD', 'SGMT', 'BOWN',\n",
       "       'SXTP', 'PWM', 'VTMX', 'INTS', 'SVV', 'KGS', 'FIHL', 'GENK',\n",
       "       'BUJA', 'BOF', 'AZTR', 'CAVA', 'ESHA', 'ATMU', 'ATS', 'IPXX',\n",
       "       'CWD', 'SGE', 'SLRN', 'ALCY', 'KVUE', 'GODN', 'TRNR', 'AACT',\n",
       "       'JYD', 'USGO', 'UCAR', 'WLGS', 'TPET', 'TCJH', 'GDTC', 'VCIG',\n",
       "       'GDHG', 'ARBB', 'ISPR', 'MGIH', 'MWG', 'HSHP', 'SFWL', 'SYT',\n",
       "       'HKIT', 'CHSN', 'TBMC', 'HLP', 'ZJYL', 'TMTC', 'YGFGF', 'OAKU',\n",
       "       'BANL', 'OMH', 'MGRX', 'FORL', 'ICG', 'IZM', 'AESI', 'AIXI',\n",
       "       'SBXC', 'BMR', 'DIST', 'GXAI', 'MARX', 'BFRG', 'ENLT', 'MLYS',\n",
       "       'PTHR', 'BLAC', 'NXT', 'HSAI', 'LSDI', 'LICN', 'GPCR', 'ASST',\n",
       "       'CETU', 'TXO', 'BREA', 'GNLX', 'QSG', 'CVKD', 'SKWD', 'ISRL',\n",
       "       'MGOL', 'SMXT', 'VHAI', 'DYCQ', 'CHRO', 'UMAC', 'TBBB', 'MGX',\n",
       "       'HLXB', 'TELO', 'KYTX', 'PMNT', 'AHR', 'LEGT', 'ANRO', 'GUTS',\n",
       "       'AS', 'FBLG', 'BTSG', 'AVBP', 'HAO', 'CGON', 'YIBO', 'SUGP', 'JL',\n",
       "       'KSPI', 'JVSA', 'PSBD', 'CCTG', 'SYNX', 'SDHC', 'ROMA'],\n",
       "      dtype=object)"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 33,
=======
     "execution_count": 189,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 33,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 189,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
     "execution_count": 33,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 197,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 34,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 197,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 34,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 34,
=======
     "execution_count": 197,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 34,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 197,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
     "execution_count": 34,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'IBACU' in list(filtered_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 192,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 35,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 192,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 35,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['Symbol'] != 'RYZB']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 193,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 36,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 193,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 36,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 36,
=======
     "execution_count": 193,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 36,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 193,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
     "execution_count": 36,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df['Symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 194,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 37,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 194,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 37,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = filtered_df['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 199,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 38,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 199,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 38,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 38,
=======
     "execution_count": 199,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
     "execution_count": 38,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
     "execution_count": 199,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
     "execution_count": 38,
>>>>>>> 2eed79c (Done with the questions for the homework2)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'IBACU' in tickers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 202,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 39,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 202,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 39,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PTHR']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DYCQ']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['LEGT']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['JVSA']: Exception(\"%ticker%: Data doesn't exist for startDate = 1672549200, endDate = 1709269200\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHLCV data for the first ticker (IROH):\n",
      "             Open   High     Low   Close  Adj Close  Volume\n",
      "Date                                                       \n",
      "2024-02-16  10.05  10.05  10.010  10.010     10.010   16700\n",
      "2024-02-20  10.02  10.02  10.020  10.020     10.020    5200\n",
      "2024-02-21  10.02  10.02  10.015  10.015     10.015   98600\n",
      "2024-02-22  10.02  10.02  10.020  10.020     10.020    5600\n",
      "2024-02-23  10.02  10.02  10.010  10.010     10.010   14800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download OHLCV data for each ticker\n",
    "ohlcvs = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        ohlcvs[ticker] = yf.download(ticker, start='2023-01-01', end='2024-03-01')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download data for ticker {ticker}: {str(e)}\")\n",
    "\n",
    "# Display the first few rows of OHLCV data for the first ticker\n",
    "if ohlcvs:\n",
    "    print(f\"OHLCV data for the first ticker ({tickers[0]}):\")\n",
    "    print(ohlcvs[tickers[0]].head())\n",
    "else:\n",
    "    print(\"No OHLCV data downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no data for ['PTHR', 'DYCQ', 'LEGT', 'JVSA']\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": null,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 40,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": null,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 40,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth_df(df:pd.DataFrame, prefix:str)->pd.DataFrame:\n",
    "  for i in [1,3,7,30,90,365]:\n",
    "    df['growth_'+prefix+'_'+str(i)+'d'] = df['Adj Close'] / df['Adj Close'].shift(i)\n",
    "    GROWTH_KEYS = [k for k in df.keys() if k.startswith('growth')]\n",
    "  return df[GROWTH_KEYS]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 204,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 41,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 204,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 41,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ticker   Min Date\n",
      "0     IROH 2024-02-16\n",
      "1     LGCB 2023-12-26\n",
      "2      ZKH 2023-12-15\n",
      "3     BAYA 2023-12-29\n",
      "4     INHD 2023-12-14\n",
      "..     ...        ...\n",
      "175   PSBD 2024-01-18\n",
      "176   CCTG 2024-01-18\n",
      "177   SYNX 2024-01-12\n",
      "178   SDHC 2024-01-16\n",
      "179   ROMA 2024-01-09\n",
      "\n",
      "[180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store DataFrames for each ticker\n",
    "min_dates_list = []\n",
    "\n",
    "# Iterate through the DataFrame containing OHLCV data for each stock\n",
    "for ticker, df in ohlcvs.items():\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        # Extract the minimum date for the current ticker\n",
    "        min_date = df.index.min()\n",
    "        # Create a DataFrame for the current ticker and its minimum date\n",
    "        min_date_df = pd.DataFrame({'Ticker': [ticker], 'Min Date': [min_date]})\n",
    "        # Append the DataFrame to the list\n",
    "        min_dates_list.append(min_date_df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "min_dates = pd.concat(min_dates_list, ignore_index=True)\n",
    "\n",
    "# Display the min_dates DataFrame\n",
    "print(min_dates)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 205,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 42,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 205,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 42,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of X (number of days to hold the stock): 28\n",
      "Max 75th percentile growth: 0.03914195622091493\n"
     ]
    }
   ],
   "source": [
    "# Define a list to store the growth for each value of X\n",
    "growth_for_X = []\n",
    "\n",
    "# Iterate over each possible value of X (from 1 to 30)\n",
    "for X in range(1, 31):\n",
    "    # Calculate the growth for each investment based on the holding period of X days\n",
    "    growths = []\n",
    "    for ticker, df in ohlcvs.items():\n",
    "        # Calculate the percentage growth from buying on the first day and selling after X days\n",
    "        if len(df) >= X + 1:  # Ensure there are enough data points for X days\n",
    "            buy_price = df.iloc[0]['Adj Close']\n",
    "            sell_price = df.iloc[X]['Adj Close']\n",
    "            growth = (sell_price - buy_price) / buy_price\n",
    "            growths.append(growth)\n",
    "\n",
    "    # Calculate the 75th percentile growth for the current value of X\n",
    "    percentile_75 = np.percentile(growths, 75)\n",
    "    # Store the 75th percentile growth for the current value of X\n",
    "    growth_for_X.append(percentile_75)\n",
    "\n",
    "# Find the value of X that maximizes the 75th percentile growth\n",
    "optimal_X = np.argmax(growth_for_X) + 1  # Add 1 because indexing starts from 0\n",
    "max_growth = max(growth_for_X)\n",
    "\n",
    "print(\"Optimal value of X (number of days to hold the stock):\", optimal_X)\n",
    "print(\"Max 75th percentile growth:\", max_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       growth_future_1d  growth_future_2d  growth_future_3d  growth_future_4d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_5d  growth_future_6d  growth_future_7d  growth_future_8d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 207,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 43,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 207,
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
   "execution_count": 43,
>>>>>>> 2eed79c (Done with the questions for the homework2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       growth_future_1d  growth_future_2d  growth_future_3d  growth_future_4d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_5d  growth_future_6d  growth_future_7d  growth_future_8d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
>>>>>>> 2eed79c (Done with the questions for the homework2)
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    # Calculate growth as before, but multiply by -1 to ensure negative returns\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) * -1 if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Is Growth Concentrated in the Largest Stocks?\n",
    "\n",
    "**Get the share of days (percentage as int) when Large Stocks outperform (growth_7d - growth over 7 periods back) the Largest stocks?**\n",
    "\n",
    "\n",
    "Reuse [Code Snippet 5] to obtain OHLCV stats for 33 stocks \n",
    "for 10 full years of data (2014-01-01 to 2023-12-31):\n",
    "\n",
    "`US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO','V', 'JPM']`\n",
    "\n",
    "`EU_STOCKS = ['NVO','MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE','IDEXY','CDI.PA']`\n",
    "\n",
    "`INDIA_STOCKS = ['RELIANCE.NS','TCS.NS','HDB','BHARTIARTL.NS','IBN','SBIN.NS','LICI.NS','INFY','ITC.NS','HINDUNILVR.NS','LT.NS']`\n",
    "\n",
    "`LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS`\n",
    "<br/>\n",
    "\n",
    "Now let's add the top 12-22 stocks (as of end-April 2024):\n",
    "<br/>\n",
    "\n",
    "`NEW_US = ['TSLA','WMT','XOM','UNH','MA','PG','JNJ','MRK','HD','COST','ORCL']`\n",
    "\n",
    "`NEW_EU = ['PRX.AS','CDI.PA','AIR.PA','SU.PA','ETN','SNY','BUD','DTE.DE','ALV.DE','MDT','AI.PA','EL.PA']`\n",
    "\n",
    "`NEW_INDIA = ['BAJFINANCE.NS','MARUTI.NS','HCLTECH.NS','TATAMOTORS.NS','SUNPHARMA.NS','ONGC.NS','ADANIENT.NS','ADANIENT.NS','NTPC.NS','KOTAKBANK.NS','TITAN.NS']`\n",
    "\n",
    "`LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA`\n",
    "\n",
    "You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS.\n",
    "\n",
    "Calculate  `growth_7d` for every stock and every day.\n",
    "Get the average daily `growth_7d` for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "For example, for the first of data you should have:\n",
    "| Date   |      ticker_category      |  growth_7d |\n",
    "|----------|:-------------:|------:|\n",
    "| 2014-01-01 |  LARGE | 1.011684 |\n",
    "| 2014-01-01 |   LARGEST   |   1.011797 |\n",
    "\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LLY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AVGO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MC.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ASML...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RMS.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for OR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ACN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SIE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IDEXY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RELIANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TCS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BHARTIARTL.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IBN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBIN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LICI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INFY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ITC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HINDUNILVR.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PRX.AS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n",
      "Fetching data for AIR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SU.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BUD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DTE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALV.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MDT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EL.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ORCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BAJFINANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MARUTI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCLTECH.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TATAMOTORS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SUNPHARMA.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ONGC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n",
      "Fetching data for NTPC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KOTAKBANK.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TITAN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks retrieved for LARGEST_STOCKS: 33\n",
      "Number of stocks retrieved for LARGE_STOCKS: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the list of ticker symbols for each group of stocks\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
    "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
    "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS', 'HINDUNILVR.NS', 'LT.NS']\n",
    "LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
    "NEW_EU = ['PRX.AS', 'CDI.PA', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
    "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS', 'ADANIENT.NS', 'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
    "LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA\n",
    "\n",
    "# Function to fetch OHLCV data for a given list of tickers and date range\n",
    "def fetch_ohlcv_data(tickers, start_date, end_date):\n",
    "    ohlcvs = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                ohlcvs[ticker] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return ohlcvs\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch OHLCV data for the LARGEST_STOCKS\n",
    "ohlcvs_largest = fetch_ohlcv_data(LARGEST_STOCKS, start_date, end_date)\n",
    "\n",
    "# Fetch OHLCV data for the LARGE_STOCKS\n",
    "ohlcvs_large = fetch_ohlcv_data(LARGE_STOCKS, start_date, end_date)\n",
    "\n",
    "# Display the number of stocks retrieved for each group\n",
    "print(f\"Number of stocks retrieved for LARGEST_STOCKS: {len(ohlcvs_largest)}\")\n",
    "print(f\"Number of stocks retrieved for LARGE_STOCKS: {len(ohlcvs_large)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Growth (LARGEST_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.013788\n",
      "2023-12-26    0.014900\n",
      "2023-12-27    0.014155\n",
      "2023-12-28    0.008533\n",
      "2023-12-29    0.005337\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n",
      "\n",
      "Average Daily Growth (LARGE_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.003809\n",
      "2023-12-26    0.014441\n",
      "2023-12-27    0.003737\n",
      "2023-12-28    0.000275\n",
      "2023-12-29    0.000244\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate 7-day growth\n",
    "def calculate_growth_7d(df):\n",
    "    df['growth_7d'] = df['Adj Close'].pct_change(periods=7)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGEST_STOCKS\n",
    "for ticker, df in ohlcvs_largest.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGE_STOCKS\n",
    "for ticker, df in ohlcvs_large.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Combine OHLCV data for LARGEST_STOCKS into a single DataFrame\n",
    "largest_df = pd.concat(ohlcvs_largest.values())\n",
    "\n",
    "# Combine OHLCV data for LARGE_STOCKS into a single DataFrame\n",
    "large_df = pd.concat(ohlcvs_large.values())\n",
    "\n",
    "# Calculate average daily growth_7d for LARGEST_STOCKS\n",
    "avg_growth_7d_largest = largest_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Calculate average daily growth_7d for LARGE_STOCKS\n",
    "avg_growth_7d_large = large_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Display the average daily growth_7d for both groups\n",
    "print(\"Average Daily Growth (LARGEST_STOCKS):\")\n",
    "print(avg_growth_7d_largest)\n",
    "print(\"\\nAverage Daily Growth (LARGE_STOCKS):\")\n",
    "print(avg_growth_7d_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of days when LARGE stocks outperform LARGEST stocks: 47 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "num_days_outperform = (avg_growth_7d_large > avg_growth_7d_largest).sum()\n",
    "\n",
    "# Calculate the percentage of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "percentage_outperform = (num_days_outperform / 2595) * 100\n",
    "\n",
    "# Convert to the closest integer value\n",
    "percentage_outperform = round(percentage_outperform)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of days when LARGE stocks outperform LARGEST stocks:\", percentage_outperform, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Trying Another Technical Indicators strategy\n",
    "\n",
    "**What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?**\n",
    "\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31).\n",
    "If you encounter any difficulties running the Colab - you can download it using this [link](https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing).\n",
    "\n",
    "Let's assume you've learned about the awesome **CCI indicator** ([Commodity Channel Index](https://www.investopedia.com/terms/c/commoditychannelindex.asp)), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (`Date.dt.dayofweek()==4`).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years?\n",
    "One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit.\n",
    "You need to sum these results over all trades (460 times in 10 years).\n",
    "\n",
    "Additional:\n",
    "  * Add an approximate fees calculation over the 460 trades from this calculator https://www.degiro.ie/fees/calculator (Product:\"Shares, USA and Canada;\" Amount per transaction: \"1000 EUR\"; Transactions per year: \"460\")\n",
    "  * are you still profitable on those trades?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('stocks_df_combined_2024_05_06.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_colab = pd.read_parquet('stocks_df_combined_trunc_2014_2023.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close_x',\n",
       " 'Volume',\n",
       " 'Ticker',\n",
       " 'Year',\n",
       " 'Month',\n",
       " 'Weekday',\n",
       " 'Date',\n",
       " 'growth_1d',\n",
       " 'growth_3d',\n",
       " 'growth_7d',\n",
       " 'growth_30d',\n",
       " 'growth_90d',\n",
       " 'growth_365d',\n",
       " 'growth_future_5d',\n",
       " 'SMA10',\n",
       " 'SMA20',\n",
       " 'growing_moving_average',\n",
       " 'high_minus_low_relative',\n",
       " 'volatility',\n",
       " 'is_positive_growth_5d_future',\n",
       " 'ticker_type',\n",
       " 'index_x',\n",
       " 'adx',\n",
       " 'adxr',\n",
       " 'apo',\n",
       " 'aroon_1',\n",
       " 'aroon_2',\n",
       " 'aroonosc',\n",
       " 'bop',\n",
       " 'cci',\n",
       " 'cmo',\n",
       " 'dx',\n",
       " 'macd',\n",
       " 'macdsignal',\n",
       " 'macdhist',\n",
       " 'macd_ext',\n",
       " 'macdsignal_ext',\n",
       " 'macdhist_ext',\n",
       " 'macd_fix',\n",
       " 'macdsignal_fix',\n",
       " 'macdhist_fix',\n",
       " 'mfi',\n",
       " 'minus_di',\n",
       " 'mom',\n",
       " 'plus_di',\n",
       " 'dm',\n",
       " 'ppo',\n",
       " 'roc',\n",
       " 'rocp',\n",
       " 'rocr',\n",
       " 'rocr100',\n",
       " 'rsi',\n",
       " 'slowk',\n",
       " 'slowd',\n",
       " 'fastk',\n",
       " 'fastd',\n",
       " 'fastk_rsi',\n",
       " 'fastd_rsi',\n",
       " 'trix',\n",
       " 'ultosc',\n",
       " 'willr',\n",
       " 'index_y',\n",
       " 'ad',\n",
       " 'adosc',\n",
       " 'obv',\n",
       " 'atr',\n",
       " 'natr',\n",
       " 'ht_dcperiod',\n",
       " 'ht_dcphase',\n",
       " 'ht_phasor_inphase',\n",
       " 'ht_phasor_quadrature',\n",
       " 'ht_sine_sine',\n",
       " 'ht_sine_leadsine',\n",
       " 'ht_trendmod',\n",
       " 'avgprice',\n",
       " 'medprice',\n",
       " 'typprice',\n",
       " 'wclprice',\n",
       " 'index',\n",
       " 'cdl2crows',\n",
       " 'cdl3blackrows',\n",
       " 'cdl3inside',\n",
       " 'cdl3linestrike',\n",
       " 'cdl3outside',\n",
       " 'cdl3starsinsouth',\n",
       " 'cdl3whitesoldiers',\n",
       " 'cdlabandonedbaby',\n",
       " 'cdladvancedblock',\n",
       " 'cdlbelthold',\n",
       " 'cdlbreakaway',\n",
       " 'cdlclosingmarubozu',\n",
       " 'cdlconcealbabyswall',\n",
       " 'cdlcounterattack',\n",
       " 'cdldarkcloudcover',\n",
       " 'cdldoji',\n",
       " 'cdldojistar',\n",
       " 'cdldragonflydoji',\n",
       " 'cdlengulfing',\n",
       " 'cdleveningdojistar',\n",
       " 'cdleveningstar',\n",
       " 'cdlgapsidesidewhite',\n",
       " 'cdlgravestonedoji',\n",
       " 'cdlhammer',\n",
       " 'cdlhangingman',\n",
       " 'cdlharami',\n",
       " 'cdlharamicross',\n",
       " 'cdlhighwave',\n",
       " 'cdlhikkake',\n",
       " 'cdlhikkakemod',\n",
       " 'cdlhomingpigeon',\n",
       " 'cdlidentical3crows',\n",
       " 'cdlinneck',\n",
       " 'cdlinvertedhammer',\n",
       " 'cdlkicking',\n",
       " 'cdlkickingbylength',\n",
       " 'cdlladderbottom',\n",
       " 'cdllongleggeddoji',\n",
       " 'cdllongline',\n",
       " 'cdlmarubozu',\n",
       " 'cdlmatchinglow',\n",
       " 'cdlmathold',\n",
       " 'cdlmorningdojistar',\n",
       " 'cdlmorningstar',\n",
       " 'cdlonneck',\n",
       " 'cdlpiercing',\n",
       " 'cdlrickshawman',\n",
       " 'cdlrisefall3methods',\n",
       " 'cdlseparatinglines',\n",
       " 'cdlshootingstar',\n",
       " 'cdlshortline',\n",
       " 'cdlspinningtop',\n",
       " 'cdlstalledpattern',\n",
       " 'cdlsticksandwich',\n",
       " 'cdltakuru',\n",
       " 'cdltasukigap',\n",
       " 'cdlthrusting',\n",
       " 'cdltristar',\n",
       " 'cdlunique3river',\n",
       " 'cdlupsidegap2crows',\n",
       " 'cdlxsidegap3methods',\n",
       " 'growth_dax_1d',\n",
       " 'growth_dax_3d',\n",
       " 'growth_dax_7d',\n",
       " 'growth_dax_30d',\n",
       " 'growth_dax_90d',\n",
       " 'growth_dax_365d',\n",
       " 'growth_snp500_1d',\n",
       " 'growth_snp500_3d',\n",
       " 'growth_snp500_7d',\n",
       " 'growth_snp500_30d',\n",
       " 'growth_snp500_90d',\n",
       " 'growth_snp500_365d',\n",
       " 'growth_dji_1d',\n",
       " 'growth_dji_3d',\n",
       " 'growth_dji_7d',\n",
       " 'growth_dji_30d',\n",
       " 'growth_dji_90d',\n",
       " 'growth_dji_365d',\n",
       " 'growth_epi_1d',\n",
       " 'growth_epi_3d',\n",
       " 'growth_epi_7d',\n",
       " 'growth_epi_30d',\n",
       " 'growth_epi_90d',\n",
       " 'growth_epi_365d',\n",
       " 'Quarter',\n",
       " 'gdppot_us_yoy',\n",
       " 'gdppot_us_qoq',\n",
       " 'cpi_core_yoy',\n",
       " 'cpi_core_mom',\n",
       " 'FEDFUNDS',\n",
       " 'DGS1',\n",
       " 'DGS5',\n",
       " 'DGS10',\n",
       " 'Adj Close_y',\n",
       " 'growth_gold_1d',\n",
       " 'growth_gold_3d',\n",
       " 'growth_gold_7d',\n",
       " 'growth_gold_30d',\n",
       " 'growth_gold_90d',\n",
       " 'growth_gold_365d',\n",
       " 'growth_wti_oil_1d',\n",
       " 'growth_wti_oil_3d',\n",
       " 'growth_wti_oil_7d',\n",
       " 'growth_wti_oil_30d',\n",
       " 'growth_wti_oil_90d',\n",
       " 'growth_wti_oil_365d',\n",
       " 'growth_brent_oil_1d',\n",
       " 'growth_brent_oil_3d',\n",
       " 'growth_brent_oil_7d',\n",
       " 'growth_brent_oil_30d',\n",
       " 'growth_brent_oil_90d',\n",
       " 'growth_brent_oil_365d',\n",
       " 'growth_btc_usd_1d',\n",
       " 'growth_btc_usd_3d',\n",
       " 'growth_btc_usd_7d',\n",
       " 'growth_btc_usd_30d',\n",
       " 'growth_btc_usd_90d',\n",
       " 'growth_btc_usd_365d']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(full_df_colab.columns)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 221109 entries, 0 to 5425\n",
      "Columns: 202 entries, Open to growth_btc_usd_365d\n",
      "dtypes: datetime64[ns](3), float64(128), int32(66), int64(3), object(2)\n",
      "memory usage: 286.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-13</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-14</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-17</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-18</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-19</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month       Date    Quarter\n",
       "0    1986-03-01 1986-03-13 1986-01-01\n",
       "1    1986-03-01 1986-03-14 1986-01-01\n",
       "2    1986-03-01 1986-03-17 1986-01-01\n",
       "3    1986-03-01 1986-03-18 1986-01-01\n",
       "4    1986-03-01 1986-03-19 1986-01-01\n",
       "...         ...        ...        ...\n",
       "5421 2024-04-01 2024-04-29 2024-04-01\n",
       "5422 2024-04-01 2024-04-30 2024-04-01\n",
       "5423 2024-05-01 2024-05-02 2024-04-01\n",
       "5424 2024-05-01 2024-05-03 2024-04-01\n",
       "5425 2024-05-01 2024-05-06 2024-04-01\n",
       "\n",
       "[221109 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.select_dtypes(include='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['TP'] = (full_df['High'] + full_df['Low'] + full_df['Close']) / 3\n",
    "full_df['SMA'] = full_df['TP'].rolling(window=20).mean()\n",
    "full_df['CCI'] = (full_df['TP'] - full_df['SMA']) / ( 0.015 * full_df['TP'].rolling(window=20).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "      <th>TP</th>\n",
       "      <th>SMA</th>\n",
       "      <th>CCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>3606.100098</td>\n",
       "      <td>3649.899902</td>\n",
       "      <td>3605.199951</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>1.396979e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>1.011533</td>\n",
       "      <td>1.001346</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.916661</td>\n",
       "      <td>1.486315</td>\n",
       "      <td>2.181200</td>\n",
       "      <td>3629.799967</td>\n",
       "      <td>3688.120833</td>\n",
       "      <td>-39.282699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1.571996e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.850046</td>\n",
       "      <td>1.423982</td>\n",
       "      <td>2.158543</td>\n",
       "      <td>3609.100016</td>\n",
       "      <td>3680.662500</td>\n",
       "      <td>-48.174406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3.748847e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931945</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.926103</td>\n",
       "      <td>0.916902</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>1.369046</td>\n",
       "      <td>2.038296</td>\n",
       "      <td>3603.233317</td>\n",
       "      <td>3669.645829</td>\n",
       "      <td>-46.877716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4.079696e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946816</td>\n",
       "      <td>1.063704</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>1.462818</td>\n",
       "      <td>2.180063</td>\n",
       "      <td>3536.750000</td>\n",
       "      <td>3655.839164</td>\n",
       "      <td>-85.763917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2.614667e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3477.133382</td>\n",
       "      <td>3640.490837</td>\n",
       "      <td>-113.935329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "0        0.088542     0.101563     0.088542     0.097222     0.060163   \n",
       "1        0.097222     0.102431     0.097222     0.100694     0.062311   \n",
       "2        0.100694     0.103299     0.100694     0.102431     0.063386   \n",
       "3        0.102431     0.103299     0.098958     0.099826     0.061774   \n",
       "4        0.099826     0.100694     0.097222     0.098090     0.060700   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5421  3606.100098  3649.899902  3605.199951  3634.300049  3634.300049   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "\n",
       "            Volume Ticker  Year      Month  Weekday  ...  \\\n",
       "0     1.031789e+09   MSFT  1986 1986-03-01        3  ...   \n",
       "1     3.081600e+08   MSFT  1986 1986-03-01        4  ...   \n",
       "2     1.331712e+08   MSFT  1986 1986-03-01        0  ...   \n",
       "3     6.776640e+07   MSFT  1986 1986-03-01        1  ...   \n",
       "4     4.789440e+07   MSFT  1986 1986-03-01        2  ...   \n",
       "...            ...    ...   ...        ...      ...  ...   \n",
       "5421  1.396979e+06  LT.NS  2024 2024-04-01        0  ...   \n",
       "5422  1.571996e+06  LT.NS  2024 2024-04-01        1  ...   \n",
       "5423  3.748847e+06  LT.NS  2024 2024-05-01        3  ...   \n",
       "5424  4.079696e+06  LT.NS  2024 2024-05-01        4  ...   \n",
       "5425  2.614667e+06  LT.NS  2024 2024-05-01        0  ...   \n",
       "\n",
       "     growth_brent_oil_365d  growth_btc_usd_1d  growth_btc_usd_3d  \\\n",
       "0                      NaN                NaN                NaN   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                      NaN                NaN                NaN   \n",
       "3                      NaN                NaN                NaN   \n",
       "4                      NaN                NaN                NaN   \n",
       "...                    ...                ...                ...   \n",
       "5421              0.949109           1.011533           1.001346   \n",
       "5422              0.936075           0.949809           0.956129   \n",
       "5423              0.931945           1.014925           0.926103   \n",
       "5424              0.946816           1.063704           1.037155   \n",
       "5425              0.954603                NaN                NaN   \n",
       "\n",
       "      growth_btc_usd_7d  growth_btc_usd_30d  growth_btc_usd_90d  \\\n",
       "0                   NaN                 NaN                 NaN   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "2                   NaN                 NaN                 NaN   \n",
       "3                   NaN                 NaN                 NaN   \n",
       "4                   NaN                 NaN                 NaN   \n",
       "...                 ...                 ...                 ...   \n",
       "5421           0.955167            0.916661            1.486315   \n",
       "5422           0.913106            0.850046            1.423982   \n",
       "5423           0.916902            0.903379            1.369046   \n",
       "5424           0.986425            0.953153            1.462818   \n",
       "5425                NaN                 NaN                 NaN   \n",
       "\n",
       "      growth_btc_usd_365d           TP          SMA         CCI  \n",
       "0                     NaN     0.095776          NaN         NaN  \n",
       "1                     NaN     0.100116          NaN         NaN  \n",
       "2                     NaN     0.102141          NaN         NaN  \n",
       "3                     NaN     0.100694          NaN         NaN  \n",
       "4                     NaN     0.098669          NaN         NaN  \n",
       "...                   ...          ...          ...         ...  \n",
       "5421             2.181200  3629.799967  3688.120833  -39.282699  \n",
       "5422             2.158543  3609.100016  3680.662500  -48.174406  \n",
       "5423             2.038296  3603.233317  3669.645829  -46.877716  \n",
       "5424             2.180063  3536.750000  3655.839164  -85.763917  \n",
       "5425                  NaN  3477.133382  3640.490837 -113.935329  \n",
       "\n",
       "[221109 rows x 205 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close_x', 'Volume', 'Ticker',\n",
       "       'Year', 'Month', 'Weekday',\n",
       "       ...\n",
       "       'growth_brent_oil_365d', 'growth_btc_usd_1d', 'growth_btc_usd_3d',\n",
       "       'growth_btc_usd_7d', 'growth_btc_usd_30d', 'growth_btc_usd_90d',\n",
       "       'growth_btc_usd_365d', 'TP', 'SMA', 'CCI'],\n",
       "      dtype='object', length=205)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_trades = full_df[(full_df['Date'].dt.dayofweek == 4) & (full_df['CCI'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>40.450001</td>\n",
       "      <td>40.970001</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>40.939999</td>\n",
       "      <td>34.912762</td>\n",
       "      <td>34567600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997447</td>\n",
       "      <td>1.005607</td>\n",
       "      <td>1.021664</td>\n",
       "      <td>0.995813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.910000</td>\n",
       "      <td>39.395618</td>\n",
       "      <td>36939400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983610</td>\n",
       "      <td>0.941627</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>45.660000</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>41.630741</td>\n",
       "      <td>130933700.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1.143658</td>\n",
       "      <td>1.055457</td>\n",
       "      <td>0.614516</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>1.037625</td>\n",
       "      <td>0.939362</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>44.270000</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>40.151123</td>\n",
       "      <td>41839000.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007958</td>\n",
       "      <td>1.032390</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>1.002560</td>\n",
       "      <td>1.009139</td>\n",
       "      <td>1.034930</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.632660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>52.299999</td>\n",
       "      <td>54.070000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>46.583046</td>\n",
       "      <td>135227100.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976399</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.751370</td>\n",
       "      <td>0.435520</td>\n",
       "      <td>1.009025</td>\n",
       "      <td>1.026100</td>\n",
       "      <td>1.051840</td>\n",
       "      <td>1.200679</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.771437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>2061.000000</td>\n",
       "      <td>2095.800049</td>\n",
       "      <td>2058.449951</td>\n",
       "      <td>2062.750000</td>\n",
       "      <td>2058.108887</td>\n",
       "      <td>2652761.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891008</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>1.124210</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.020511</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.795450</td>\n",
       "      <td>0.824372</td>\n",
       "      <td>0.288467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2483.500000</td>\n",
       "      <td>2415.050049</td>\n",
       "      <td>2475.550049</td>\n",
       "      <td>2469.979980</td>\n",
       "      <td>2690699.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971214</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.901866</td>\n",
       "      <td>0.870323</td>\n",
       "      <td>1.001048</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>1.119678</td>\n",
       "      <td>1.072726</td>\n",
       "      <td>1.540443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2521.100098</td>\n",
       "      <td>2586.250000</td>\n",
       "      <td>2580.430908</td>\n",
       "      <td>4610417.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011984</td>\n",
       "      <td>1.053541</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>0.869197</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>1.075177</td>\n",
       "      <td>1.291138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2928.699951</td>\n",
       "      <td>2872.449951</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>3638510.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060358</td>\n",
       "      <td>1.076092</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.751347</td>\n",
       "      <td>0.987251</td>\n",
       "      <td>1.004875</td>\n",
       "      <td>1.004067</td>\n",
       "      <td>0.876331</td>\n",
       "      <td>1.002105</td>\n",
       "      <td>1.340190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>3129.949951</td>\n",
       "      <td>3197.949951</td>\n",
       "      <td>3121.050049</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>2112908.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962421</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.936372</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>1.025880</td>\n",
       "      <td>1.022671</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>1.091754</td>\n",
       "      <td>1.495576</td>\n",
       "      <td>2.280217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "7113    40.450001    40.970001    40.250000    40.939999    34.912762   \n",
       "7181    45.110001    45.930000    45.110001    45.910000    39.395618   \n",
       "7340    45.660000    48.139999    45.650002    47.869999    41.630741   \n",
       "7452    44.270000    45.570000    43.919998    45.570000    40.151123   \n",
       "7467    52.299999    54.070000    52.250000    52.869999    46.583046   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5072  2061.000000  2095.800049  2058.449951  2062.750000  2058.108887   \n",
       "5219  2420.000000  2483.500000  2415.050049  2475.550049  2469.979980   \n",
       "5234  2522.000000  2595.000000  2521.100098  2586.250000  2580.430908   \n",
       "5268  2888.000000  2928.699951  2872.449951  2901.600098  2901.600098   \n",
       "5323  3129.949951  3197.949951  3121.050049  3190.649902  3190.649902   \n",
       "\n",
       "           Volume Ticker  Year      Month  Weekday  ... growth_brent_oil_7d  \\\n",
       "7113   34567600.0   MSFT  2014 2014-05-01        4  ...            0.997447   \n",
       "7181   36939400.0   MSFT  2014 2014-09-01        4  ...            0.983610   \n",
       "7340  130933700.0   MSFT  2015 2015-04-01        4  ...            1.082228   \n",
       "7452   41839000.0   MSFT  2015 2015-10-01        4  ...            1.007958   \n",
       "7467  135227100.0   MSFT  2015 2015-10-01        4  ...            0.976399   \n",
       "...           ...    ...   ...        ...      ...  ...                 ...   \n",
       "5072    2652761.0  LT.NS  2022 2022-11-01        4  ...            0.891008   \n",
       "5219    2690699.0  LT.NS  2023 2023-06-01        4  ...            0.971214   \n",
       "5234    4610417.0  LT.NS  2023 2023-07-01        4  ...            1.011984   \n",
       "5268    3638510.0  LT.NS  2023 2023-09-01        4  ...            1.060358   \n",
       "5323    2112908.0  LT.NS  2023 2023-12-01        4  ...            0.962421   \n",
       "\n",
       "      growth_brent_oil_30d  growth_brent_oil_90d  growth_brent_oil_365d  \\\n",
       "7113              1.005607              1.021664               0.995813   \n",
       "7181              0.941627              0.925124               0.914716   \n",
       "7340              1.143658              1.055457               0.614516   \n",
       "7452              1.032390              0.775540               0.441114   \n",
       "7467              0.996884              0.751370               0.435520   \n",
       "...                    ...                   ...                    ...   \n",
       "5072              0.884318              0.782174               1.124210   \n",
       "5219              0.973233              0.901866               0.870323   \n",
       "5234              1.053541              1.003714               0.869197   \n",
       "5268              1.076092              1.142983               0.751347   \n",
       "5323              0.855903              0.936372               0.705924   \n",
       "\n",
       "      growth_btc_usd_1d  growth_btc_usd_3d  growth_btc_usd_7d  \\\n",
       "7113                NaN                NaN                NaN   \n",
       "7181                NaN                NaN                NaN   \n",
       "7340           0.978035           0.982994           1.037625   \n",
       "7452           0.998922           1.002560           1.009139   \n",
       "7467           1.009025           1.026100           1.051840   \n",
       "...                 ...                ...                ...   \n",
       "5072           0.995024           1.020511           0.989464   \n",
       "5219           1.001048           0.993127           0.992891   \n",
       "5234           1.003918           1.001748           0.985979   \n",
       "5268           0.987251           1.004875           1.004067   \n",
       "5323           1.025880           1.022671           1.025675   \n",
       "\n",
       "      growth_btc_usd_30d  growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "7113                 NaN                 NaN                  NaN  \n",
       "7181                 NaN                 NaN                  NaN  \n",
       "7340            0.939362            0.933108                  NaN  \n",
       "7452            1.034930            0.909566             0.632660  \n",
       "7467            1.200679            0.957738             0.771437  \n",
       "...                  ...                 ...                  ...  \n",
       "5072            0.795450            0.824372             0.288467  \n",
       "5219            1.119678            1.072726             1.540443  \n",
       "5234            0.996052            1.075177             1.291138  \n",
       "5268            0.876331            1.002105             1.340190  \n",
       "5323            1.091754            1.495576             2.280217  \n",
       "\n",
       "[460 rows x 202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades_colab = full_df_colab[(full_df_colab['Date'].dt.dayofweek == 4) & (full_df_colab['cci']>200)]\n",
    "qualifying_trades_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-04-27 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1986-04-30 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected gross profit (in thousands of dollars): -7\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to store gross profit\n",
    "gross_profit = 0\n",
    "\n",
    "# Iterate through each qualifying trade\n",
    "for index,row in qualifying_trades.iterrows():\n",
    "    # Calculate the buy price (Adj. Close price)\n",
    "    buy_price = row['Adj Close_x']\n",
    "    #print(buy_price, 'buy')\n",
    "    # Try to find the sell price after 5 trading days\n",
    "    try:\n",
    "        sell_price = full_df_colab.loc[(full_df_colab['Date']==full_df_colab.iloc[index]['Date'] + pd.Timedelta(days=5))  & (full_df_colab['Ticker']==row['Ticker'])]['growth_future_5d'].iloc[0]\n",
    "        #print(sell_price, 'sell')\n",
    "    except KeyError and IndexError:\n",
    "        # If there are not enough trading days in the future, skip this trade\n",
    "        continue\n",
    "    \n",
    "    # Calculate the profit or loss from this trade\n",
    "    trade_profit = (sell_price - buy_price) * (1000 / buy_price)\n",
    "    #print(trade_profit, 'profit')\n",
    "    gross_profit += trade_profit\n",
    "\n",
    "# Convert the gross profit to thousands of dollars and round to the nearest integer\n",
    "gross_profit_thousands = round(gross_profit/1000)\n",
    "\n",
    "# Display the expected gross profit\n",
    "print(\"Expected gross profit (in thousands of dollars):\", gross_profit_thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, I would try to make the scope smaller. Look for growth and performance in several industries. Other step would be probably to read news about how is the market demand and the sentiment in general for those IPO. Finally, is not a bad idea on check for experts opinions. \n",
    "I think the best way to analyse an IPO is to make a smart comparison against existing stocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
=======
=======
>>>>>>> 4ce4663 (almost add question 2 response)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Is Growth Concentrated in the Largest Stocks?\n",
    "\n",
    "**Get the share of days (percentage as int) when Large Stocks outperform (growth_7d - growth over 7 periods back) the Largest stocks?**\n",
    "\n",
    "\n",
    "Reuse [Code Snippet 5] to obtain OHLCV stats for 33 stocks \n",
    "for 10 full years of data (2014-01-01 to 2023-12-31):\n",
    "\n",
    "`US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO','V', 'JPM']`\n",
    "\n",
    "`EU_STOCKS = ['NVO','MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE','IDEXY','CDI.PA']`\n",
    "\n",
    "`INDIA_STOCKS = ['RELIANCE.NS','TCS.NS','HDB','BHARTIARTL.NS','IBN','SBIN.NS','LICI.NS','INFY','ITC.NS','HINDUNILVR.NS','LT.NS']`\n",
    "\n",
    "`LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS`\n",
    "<br/>\n",
    "\n",
    "Now let's add the top 12-22 stocks (as of end-April 2024):\n",
    "<br/>\n",
    "\n",
    "`NEW_US = ['TSLA','WMT','XOM','UNH','MA','PG','JNJ','MRK','HD','COST','ORCL']`\n",
    "\n",
    "`NEW_EU = ['PRX.AS','CDI.PA','AIR.PA','SU.PA','ETN','SNY','BUD','DTE.DE','ALV.DE','MDT','AI.PA','EL.PA']`\n",
    "\n",
    "`NEW_INDIA = ['BAJFINANCE.NS','MARUTI.NS','HCLTECH.NS','TATAMOTORS.NS','SUNPHARMA.NS','ONGC.NS','ADANIENT.NS','ADANIENT.NS','NTPC.NS','KOTAKBANK.NS','TITAN.NS']`\n",
    "\n",
    "`LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA`\n",
    "\n",
    "You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS.\n",
    "\n",
    "Calculate  `growth_7d` for every stock and every day.\n",
    "Get the average daily `growth_7d` for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "For example, for the first of data you should have:\n",
    "| Date   |      ticker_category      |  growth_7d |\n",
    "|----------|:-------------:|------:|\n",
    "| 2014-01-01 |  LARGE | 1.011684 |\n",
    "| 2014-01-01 |   LARGEST   |   1.011797 |\n",
    "\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
<<<<<<< HEAD
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n",
    "\n",
    "---\n",
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw02\n",
    "\n",
    "-"
   ]
>>>>>>> a1fa175 (Add response to first question)
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LLY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AVGO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MC.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ASML...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RMS.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for OR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ACN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SIE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IDEXY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RELIANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TCS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BHARTIARTL.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IBN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBIN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LICI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INFY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ITC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HINDUNILVR.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PRX.AS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n",
      "Fetching data for AIR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SU.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BUD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DTE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALV.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MDT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EL.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ORCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BAJFINANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MARUTI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCLTECH.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TATAMOTORS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SUNPHARMA.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ONGC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n",
      "Fetching data for NTPC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KOTAKBANK.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TITAN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks retrieved for LARGEST_STOCKS: 33\n",
      "Number of stocks retrieved for LARGE_STOCKS: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the list of ticker symbols for each group of stocks\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
    "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
    "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS', 'HINDUNILVR.NS', 'LT.NS']\n",
    "LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
    "NEW_EU = ['PRX.AS', 'CDI.PA', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
    "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS', 'ADANIENT.NS', 'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
    "LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA\n",
    "\n",
    "# Function to fetch OHLCV data for a given list of tickers and date range\n",
    "def fetch_ohlcv_data(tickers, start_date, end_date):\n",
    "    ohlcvs = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                ohlcvs[ticker] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return ohlcvs\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch OHLCV data for the LARGEST_STOCKS\n",
    "ohlcvs_largest = fetch_ohlcv_data(LARGEST_STOCKS, start_date, end_date)\n",
    "\n",
    "# Fetch OHLCV data for the LARGE_STOCKS\n",
    "ohlcvs_large = fetch_ohlcv_data(LARGE_STOCKS, start_date, end_date)\n",
    "\n",
    "# Display the number of stocks retrieved for each group\n",
    "print(f\"Number of stocks retrieved for LARGEST_STOCKS: {len(ohlcvs_largest)}\")\n",
    "print(f\"Number of stocks retrieved for LARGE_STOCKS: {len(ohlcvs_large)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Growth (LARGEST_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.013788\n",
      "2023-12-26    0.014900\n",
      "2023-12-27    0.014155\n",
      "2023-12-28    0.008533\n",
      "2023-12-29    0.005337\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n",
      "\n",
      "Average Daily Growth (LARGE_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.003809\n",
      "2023-12-26    0.014441\n",
      "2023-12-27    0.003737\n",
      "2023-12-28    0.000275\n",
      "2023-12-29    0.000244\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate 7-day growth\n",
    "def calculate_growth_7d(df):\n",
    "    df['growth_7d'] = df['Adj Close'].pct_change(periods=7)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGEST_STOCKS\n",
    "for ticker, df in ohlcvs_largest.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGE_STOCKS\n",
    "for ticker, df in ohlcvs_large.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Combine OHLCV data for LARGEST_STOCKS into a single DataFrame\n",
    "largest_df = pd.concat(ohlcvs_largest.values())\n",
    "\n",
    "# Combine OHLCV data for LARGE_STOCKS into a single DataFrame\n",
    "large_df = pd.concat(ohlcvs_large.values())\n",
    "\n",
    "# Calculate average daily growth_7d for LARGEST_STOCKS\n",
    "avg_growth_7d_largest = largest_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Calculate average daily growth_7d for LARGE_STOCKS\n",
    "avg_growth_7d_large = large_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Display the average daily growth_7d for both groups\n",
    "print(\"Average Daily Growth (LARGEST_STOCKS):\")\n",
    "print(avg_growth_7d_largest)\n",
    "print(\"\\nAverage Daily Growth (LARGE_STOCKS):\")\n",
    "print(avg_growth_7d_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of days when LARGE stocks outperform LARGEST stocks: 47 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "num_days_outperform = (avg_growth_7d_large > avg_growth_7d_largest).sum()\n",
    "\n",
    "# Calculate the percentage of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "percentage_outperform = (num_days_outperform / 2595) * 100\n",
    "\n",
    "# Convert to the closest integer value\n",
    "percentage_outperform = round(percentage_outperform)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of days when LARGE stocks outperform LARGEST stocks:\", percentage_outperform, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Trying Another Technical Indicators strategy\n",
    "\n",
    "**What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?**\n",
    "\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31).\n",
    "If you encounter any difficulties running the Colab - you can download it using this [link](https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing).\n",
    "\n",
    "Let's assume you've learned about the awesome **CCI indicator** ([Commodity Channel Index](https://www.investopedia.com/terms/c/commoditychannelindex.asp)), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (`Date.dt.dayofweek()==4`).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years?\n",
    "One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit.\n",
    "You need to sum these results over all trades (460 times in 10 years).\n",
    "\n",
    "Additional:\n",
    "  * Add an approximate fees calculation over the 460 trades from this calculator https://www.degiro.ie/fees/calculator (Product:\"Shares, USA and Canada;\" Amount per transaction: \"1000 EUR\"; Transactions per year: \"460\")\n",
    "  * are you still profitable on those trades?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('stocks_df_combined_2024_05_06.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 9df35aa (Trying to solve question 4 but not yet)
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 221109 entries, 0 to 5425\n",
      "Columns: 202 entries, Open to growth_btc_usd_365d\n",
      "dtypes: datetime64[ns](3), float64(128), int32(66), int64(3), object(2)\n",
      "memory usage: 286.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-13</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-14</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-17</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-18</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-19</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month       Date    Quarter\n",
       "0    1986-03-01 1986-03-13 1986-01-01\n",
       "1    1986-03-01 1986-03-14 1986-01-01\n",
       "2    1986-03-01 1986-03-17 1986-01-01\n",
       "3    1986-03-01 1986-03-18 1986-01-01\n",
       "4    1986-03-01 1986-03-19 1986-01-01\n",
       "...         ...        ...        ...\n",
       "5421 2024-04-01 2024-04-29 2024-04-01\n",
       "5422 2024-04-01 2024-04-30 2024-04-01\n",
       "5423 2024-05-01 2024-05-02 2024-04-01\n",
       "5424 2024-05-01 2024-05-03 2024-04-01\n",
       "5425 2024-05-01 2024-05-06 2024-04-01\n",
       "\n",
       "[221109 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.select_dtypes(include='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['TP'] = (full_df['High'] + full_df['Low'] + full_df['Close']) / 3\n",
    "full_df['SMA'] = full_df['TP'].rolling(window=20).mean()\n",
    "full_df['CCI'] = (full_df['TP'] - full_df['SMA']) / ( 0.015 * full_df['TP'].rolling(window=20).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "      <th>TP</th>\n",
       "      <th>SMA</th>\n",
       "      <th>CCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>3606.100098</td>\n",
       "      <td>3649.899902</td>\n",
       "      <td>3605.199951</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>1.396979e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>1.011533</td>\n",
       "      <td>1.001346</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.916661</td>\n",
       "      <td>1.486315</td>\n",
       "      <td>2.181200</td>\n",
       "      <td>3629.799967</td>\n",
       "      <td>3688.120833</td>\n",
       "      <td>-39.282699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1.571996e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.850046</td>\n",
       "      <td>1.423982</td>\n",
       "      <td>2.158543</td>\n",
       "      <td>3609.100016</td>\n",
       "      <td>3680.662500</td>\n",
       "      <td>-48.174406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3.748847e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931945</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.926103</td>\n",
       "      <td>0.916902</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>1.369046</td>\n",
       "      <td>2.038296</td>\n",
       "      <td>3603.233317</td>\n",
       "      <td>3669.645829</td>\n",
       "      <td>-46.877716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4.079696e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946816</td>\n",
       "      <td>1.063704</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>1.462818</td>\n",
       "      <td>2.180063</td>\n",
       "      <td>3536.750000</td>\n",
       "      <td>3655.839164</td>\n",
       "      <td>-85.763917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2.614667e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3477.133382</td>\n",
       "      <td>3640.490837</td>\n",
       "      <td>-113.935329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "0        0.088542     0.101563     0.088542     0.097222     0.060163   \n",
       "1        0.097222     0.102431     0.097222     0.100694     0.062311   \n",
       "2        0.100694     0.103299     0.100694     0.102431     0.063386   \n",
       "3        0.102431     0.103299     0.098958     0.099826     0.061774   \n",
       "4        0.099826     0.100694     0.097222     0.098090     0.060700   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5421  3606.100098  3649.899902  3605.199951  3634.300049  3634.300049   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "\n",
       "            Volume Ticker  Year      Month  Weekday  ...  \\\n",
       "0     1.031789e+09   MSFT  1986 1986-03-01        3  ...   \n",
       "1     3.081600e+08   MSFT  1986 1986-03-01        4  ...   \n",
       "2     1.331712e+08   MSFT  1986 1986-03-01        0  ...   \n",
       "3     6.776640e+07   MSFT  1986 1986-03-01        1  ...   \n",
       "4     4.789440e+07   MSFT  1986 1986-03-01        2  ...   \n",
       "...            ...    ...   ...        ...      ...  ...   \n",
       "5421  1.396979e+06  LT.NS  2024 2024-04-01        0  ...   \n",
       "5422  1.571996e+06  LT.NS  2024 2024-04-01        1  ...   \n",
       "5423  3.748847e+06  LT.NS  2024 2024-05-01        3  ...   \n",
       "5424  4.079696e+06  LT.NS  2024 2024-05-01        4  ...   \n",
       "5425  2.614667e+06  LT.NS  2024 2024-05-01        0  ...   \n",
       "\n",
       "     growth_brent_oil_365d  growth_btc_usd_1d  growth_btc_usd_3d  \\\n",
       "0                      NaN                NaN                NaN   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                      NaN                NaN                NaN   \n",
       "3                      NaN                NaN                NaN   \n",
       "4                      NaN                NaN                NaN   \n",
       "...                    ...                ...                ...   \n",
       "5421              0.949109           1.011533           1.001346   \n",
       "5422              0.936075           0.949809           0.956129   \n",
       "5423              0.931945           1.014925           0.926103   \n",
       "5424              0.946816           1.063704           1.037155   \n",
       "5425              0.954603                NaN                NaN   \n",
       "\n",
       "      growth_btc_usd_7d  growth_btc_usd_30d  growth_btc_usd_90d  \\\n",
       "0                   NaN                 NaN                 NaN   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "2                   NaN                 NaN                 NaN   \n",
       "3                   NaN                 NaN                 NaN   \n",
       "4                   NaN                 NaN                 NaN   \n",
       "...                 ...                 ...                 ...   \n",
       "5421           0.955167            0.916661            1.486315   \n",
       "5422           0.913106            0.850046            1.423982   \n",
       "5423           0.916902            0.903379            1.369046   \n",
       "5424           0.986425            0.953153            1.462818   \n",
       "5425                NaN                 NaN                 NaN   \n",
       "\n",
       "      growth_btc_usd_365d           TP          SMA         CCI  \n",
       "0                     NaN     0.095776          NaN         NaN  \n",
       "1                     NaN     0.100116          NaN         NaN  \n",
       "2                     NaN     0.102141          NaN         NaN  \n",
       "3                     NaN     0.100694          NaN         NaN  \n",
       "4                     NaN     0.098669          NaN         NaN  \n",
       "...                   ...          ...          ...         ...  \n",
       "5421             2.181200  3629.799967  3688.120833  -39.282699  \n",
       "5422             2.158543  3609.100016  3680.662500  -48.174406  \n",
       "5423             2.038296  3603.233317  3669.645829  -46.877716  \n",
       "5424             2.180063  3536.750000  3655.839164  -85.763917  \n",
       "5425                  NaN  3477.133382  3640.490837 -113.935329  \n",
       "\n",
       "[221109 rows x 205 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close_x', 'Volume', 'Ticker',\n",
       "       'Year', 'Month', 'Weekday',\n",
       "       ...\n",
       "       'growth_brent_oil_365d', 'growth_btc_usd_1d', 'growth_btc_usd_3d',\n",
       "       'growth_btc_usd_7d', 'growth_btc_usd_30d', 'growth_btc_usd_90d',\n",
       "       'growth_btc_usd_365d', 'TP', 'SMA', 'CCI'],\n",
       "      dtype='object', length=205)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_trades = full_df[(full_df['Date'].dt.dayofweek == 4) & (full_df['CCI'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>40.450001</td>\n",
       "      <td>40.970001</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>40.939999</td>\n",
       "      <td>34.912762</td>\n",
       "      <td>34567600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997447</td>\n",
       "      <td>1.005607</td>\n",
       "      <td>1.021664</td>\n",
       "      <td>0.995813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.910000</td>\n",
       "      <td>39.395618</td>\n",
       "      <td>36939400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983610</td>\n",
       "      <td>0.941627</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>45.660000</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>41.630741</td>\n",
       "      <td>130933700.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1.143658</td>\n",
       "      <td>1.055457</td>\n",
       "      <td>0.614516</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>1.037625</td>\n",
       "      <td>0.939362</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>44.270000</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>40.151123</td>\n",
       "      <td>41839000.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007958</td>\n",
       "      <td>1.032390</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>1.002560</td>\n",
       "      <td>1.009139</td>\n",
       "      <td>1.034930</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.632660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>52.299999</td>\n",
       "      <td>54.070000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>46.583046</td>\n",
       "      <td>135227100.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976399</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.751370</td>\n",
       "      <td>0.435520</td>\n",
       "      <td>1.009025</td>\n",
       "      <td>1.026100</td>\n",
       "      <td>1.051840</td>\n",
       "      <td>1.200679</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.771437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>2061.000000</td>\n",
       "      <td>2095.800049</td>\n",
       "      <td>2058.449951</td>\n",
       "      <td>2062.750000</td>\n",
       "      <td>2058.108887</td>\n",
       "      <td>2652761.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891008</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>1.124210</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.020511</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.795450</td>\n",
       "      <td>0.824372</td>\n",
       "      <td>0.288467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2483.500000</td>\n",
       "      <td>2415.050049</td>\n",
       "      <td>2475.550049</td>\n",
       "      <td>2469.979980</td>\n",
       "      <td>2690699.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971214</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.901866</td>\n",
       "      <td>0.870323</td>\n",
       "      <td>1.001048</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>1.119678</td>\n",
       "      <td>1.072726</td>\n",
       "      <td>1.540443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2521.100098</td>\n",
       "      <td>2586.250000</td>\n",
       "      <td>2580.430908</td>\n",
       "      <td>4610417.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011984</td>\n",
       "      <td>1.053541</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>0.869197</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>1.075177</td>\n",
       "      <td>1.291138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2928.699951</td>\n",
       "      <td>2872.449951</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>3638510.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060358</td>\n",
       "      <td>1.076092</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.751347</td>\n",
       "      <td>0.987251</td>\n",
       "      <td>1.004875</td>\n",
       "      <td>1.004067</td>\n",
       "      <td>0.876331</td>\n",
       "      <td>1.002105</td>\n",
       "      <td>1.340190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>3129.949951</td>\n",
       "      <td>3197.949951</td>\n",
       "      <td>3121.050049</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>2112908.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962421</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.936372</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>1.025880</td>\n",
       "      <td>1.022671</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>1.091754</td>\n",
       "      <td>1.495576</td>\n",
       "      <td>2.280217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "7113    40.450001    40.970001    40.250000    40.939999    34.912762   \n",
       "7181    45.110001    45.930000    45.110001    45.910000    39.395618   \n",
       "7340    45.660000    48.139999    45.650002    47.869999    41.630741   \n",
       "7452    44.270000    45.570000    43.919998    45.570000    40.151123   \n",
       "7467    52.299999    54.070000    52.250000    52.869999    46.583046   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5072  2061.000000  2095.800049  2058.449951  2062.750000  2058.108887   \n",
       "5219  2420.000000  2483.500000  2415.050049  2475.550049  2469.979980   \n",
       "5234  2522.000000  2595.000000  2521.100098  2586.250000  2580.430908   \n",
       "5268  2888.000000  2928.699951  2872.449951  2901.600098  2901.600098   \n",
       "5323  3129.949951  3197.949951  3121.050049  3190.649902  3190.649902   \n",
       "\n",
       "           Volume Ticker  Year      Month  Weekday  ... growth_brent_oil_7d  \\\n",
       "7113   34567600.0   MSFT  2014 2014-05-01        4  ...            0.997447   \n",
       "7181   36939400.0   MSFT  2014 2014-09-01        4  ...            0.983610   \n",
       "7340  130933700.0   MSFT  2015 2015-04-01        4  ...            1.082228   \n",
       "7452   41839000.0   MSFT  2015 2015-10-01        4  ...            1.007958   \n",
       "7467  135227100.0   MSFT  2015 2015-10-01        4  ...            0.976399   \n",
       "...           ...    ...   ...        ...      ...  ...                 ...   \n",
       "5072    2652761.0  LT.NS  2022 2022-11-01        4  ...            0.891008   \n",
       "5219    2690699.0  LT.NS  2023 2023-06-01        4  ...            0.971214   \n",
       "5234    4610417.0  LT.NS  2023 2023-07-01        4  ...            1.011984   \n",
       "5268    3638510.0  LT.NS  2023 2023-09-01        4  ...            1.060358   \n",
       "5323    2112908.0  LT.NS  2023 2023-12-01        4  ...            0.962421   \n",
       "\n",
       "      growth_brent_oil_30d  growth_brent_oil_90d  growth_brent_oil_365d  \\\n",
       "7113              1.005607              1.021664               0.995813   \n",
       "7181              0.941627              0.925124               0.914716   \n",
       "7340              1.143658              1.055457               0.614516   \n",
       "7452              1.032390              0.775540               0.441114   \n",
       "7467              0.996884              0.751370               0.435520   \n",
       "...                    ...                   ...                    ...   \n",
       "5072              0.884318              0.782174               1.124210   \n",
       "5219              0.973233              0.901866               0.870323   \n",
       "5234              1.053541              1.003714               0.869197   \n",
       "5268              1.076092              1.142983               0.751347   \n",
       "5323              0.855903              0.936372               0.705924   \n",
       "\n",
       "      growth_btc_usd_1d  growth_btc_usd_3d  growth_btc_usd_7d  \\\n",
       "7113                NaN                NaN                NaN   \n",
       "7181                NaN                NaN                NaN   \n",
       "7340           0.978035           0.982994           1.037625   \n",
       "7452           0.998922           1.002560           1.009139   \n",
       "7467           1.009025           1.026100           1.051840   \n",
       "...                 ...                ...                ...   \n",
       "5072           0.995024           1.020511           0.989464   \n",
       "5219           1.001048           0.993127           0.992891   \n",
       "5234           1.003918           1.001748           0.985979   \n",
       "5268           0.987251           1.004875           1.004067   \n",
       "5323           1.025880           1.022671           1.025675   \n",
       "\n",
       "      growth_btc_usd_30d  growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "7113                 NaN                 NaN                  NaN  \n",
       "7181                 NaN                 NaN                  NaN  \n",
       "7340            0.939362            0.933108                  NaN  \n",
       "7452            1.034930            0.909566             0.632660  \n",
       "7467            1.200679            0.957738             0.771437  \n",
       "...                  ...                 ...                  ...  \n",
       "5072            0.795450            0.824372             0.288467  \n",
       "5219            1.119678            1.072726             1.540443  \n",
       "5234            0.996052            1.075177             1.291138  \n",
       "5268            0.876331            1.002105             1.340190  \n",
       "5323            1.091754            1.495576             2.280217  \n",
       "\n",
       "[460 rows x 202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades_colab = full_df_colab[(full_df_colab['Date'].dt.dayofweek == 4) & (full_df_colab['cci']>200)]\n",
    "qualifying_trades_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-04-27 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1986-04-30 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[30]['Date'] + pd.Timedelta(days=5)"
=======
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 207,
>>>>>>> 4ce4663 (almost add question 2 response)
=======
   "execution_count": 43,
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
   "execution_count": 43,
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Expected gross profit (in thousands of dollars): -7\n"
=======
      "       growth_future_1d  growth_future_2d  growth_future_3d  growth_future_4d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_5d  growth_future_6d  growth_future_7d  growth_future_8d  \\\n",
      "count               0.0               0.0               0.0               0.0   \n",
      "mean                NaN               NaN               NaN               NaN   \n",
      "min                 NaN               NaN               NaN               NaN   \n",
      "25%                 NaN               NaN               NaN               NaN   \n",
      "50%                 NaN               NaN               NaN               NaN   \n",
      "75%                 NaN               NaN               NaN               NaN   \n",
      "max                 NaN               NaN               NaN               NaN   \n",
      "std                 NaN               NaN               NaN               NaN   \n",
      "\n",
      "       growth_future_9d  growth_future_10d  ...  growth_future_22d  \\\n",
      "count               0.0                0.0  ...                0.0   \n",
      "mean                NaN                NaN  ...                NaN   \n",
      "min                 NaN                NaN  ...                NaN   \n",
      "25%                 NaN                NaN  ...                NaN   \n",
      "50%                 NaN                NaN  ...                NaN   \n",
      "75%                 NaN                NaN  ...                NaN   \n",
      "max                 NaN                NaN  ...                NaN   \n",
      "std                 NaN                NaN  ...                NaN   \n",
      "\n",
      "       growth_future_23d  growth_future_24d  growth_future_25d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_26d  growth_future_27d  growth_future_28d  \\\n",
      "count                0.0                0.0                0.0   \n",
      "mean                 NaN                NaN                NaN   \n",
      "min                  NaN                NaN                NaN   \n",
      "25%                  NaN                NaN                NaN   \n",
      "50%                  NaN                NaN                NaN   \n",
      "75%                  NaN                NaN                NaN   \n",
      "max                  NaN                NaN                NaN   \n",
      "std                  NaN                NaN                NaN   \n",
      "\n",
      "       growth_future_29d  growth_future_30d  Min Date  \n",
      "count                0.0                0.0         0  \n",
      "mean                 NaN                NaN       NaT  \n",
      "min                  NaN                NaN       NaT  \n",
      "25%                  NaN                NaN       NaT  \n",
      "50%                  NaN                NaN       NaT  \n",
      "75%                  NaN                NaN       NaT  \n",
      "max                  NaN                NaN       NaT  \n",
      "std                  NaN                NaN       NaN  \n",
      "\n",
      "[8 rows x 31 columns]\n"
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Initialize variable to store gross profit\n",
    "gross_profit = 0\n",
    "\n",
    "# Iterate through each qualifying trade\n",
    "for index,row in qualifying_trades.iterrows():\n",
    "    # Calculate the buy price (Adj. Close price)\n",
    "    buy_price = row['Adj Close_x']\n",
    "    #print(buy_price, 'buy')\n",
    "    # Try to find the sell price after 5 trading days\n",
    "    try:\n",
    "        sell_price = full_df_colab.loc[(full_df_colab['Date']==full_df_colab.iloc[index]['Date'] + pd.Timedelta(days=5))  & (full_df_colab['Ticker']==row['Ticker'])]['growth_future_5d'].iloc[0]\n",
    "        #print(sell_price, 'sell')\n",
    "    except KeyError and IndexError:\n",
    "        # If there are not enough trading days in the future, skip this trade\n",
    "        continue\n",
    "    \n",
    "    # Calculate the profit or loss from this trade\n",
    "    trade_profit = (sell_price - buy_price) * (1000 / buy_price)\n",
    "    #print(trade_profit, 'profit')\n",
    "    gross_profit += trade_profit\n",
    "\n",
    "# Convert the gross profit to thousands of dollars and round to the nearest integer\n",
    "gross_profit_thousands = round(gross_profit/1000)\n",
    "\n",
    "# Display the expected gross profit\n",
    "print(\"Expected gross profit (in thousands of dollars):\", gross_profit_thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, I would try to make the scope smaller. Look for growth and performance in several industries. Other step would be probably to read news about how is the market demand and the sentiment in general for those IPO. Finally, is not a bad idea on check for experts opinions. \n",
    "I think the best way to analyse an IPO is to make a smart comparison against existing stocks. "
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2269700 (previous changes hw2)
=======
=======
>>>>>>> 3fc6c15 (almost add question 2 response)
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
>>>>>>> 4ce4663 (almost add question 2 response)
=======
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
    "# Define a DataFrame to store the growth for each investment over future holding periods\n",
    "growth_df = pd.DataFrame(index=ohlcvs.keys())\n",
    "\n",
    "# Calculate growth for each holding period (1 day to 30 days)\n",
    "for i in range(1, 31):\n",
    "    # Calculate growth as before, but multiply by -1 to ensure negative returns\n",
    "    growth_df[f\"growth_future_{i}d\"] = [((ohlcvs[ticker].iloc[i]['Adj Close'] - ohlcvs[ticker].iloc[0]['Adj Close']) / ohlcvs[ticker].iloc[0]['Adj Close']) * -1 if len(ohlcvs[ticker]) > i else np.nan for ticker in growth_df.index]\n",
    "\n",
    "# Join growth_df with the table of min_dates\n",
    "merged_df = pd.merge(growth_df, min_dates, left_index=True, right_index=True)\n",
    "\n",
    "# Perform vector operations on the resulting dataset\n",
    "# For example, calculate the mean, min, max, and quantiles\n",
    "statistics = merged_df.describe()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Is Growth Concentrated in the Largest Stocks?\n",
    "\n",
    "**Get the share of days (percentage as int) when Large Stocks outperform (growth_7d - growth over 7 periods back) the Largest stocks?**\n",
    "\n",
    "\n",
    "Reuse [Code Snippet 5] to obtain OHLCV stats for 33 stocks \n",
    "for 10 full years of data (2014-01-01 to 2023-12-31):\n",
    "\n",
    "`US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO','V', 'JPM']`\n",
    "\n",
    "`EU_STOCKS = ['NVO','MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE','IDEXY','CDI.PA']`\n",
    "\n",
    "`INDIA_STOCKS = ['RELIANCE.NS','TCS.NS','HDB','BHARTIARTL.NS','IBN','SBIN.NS','LICI.NS','INFY','ITC.NS','HINDUNILVR.NS','LT.NS']`\n",
    "\n",
    "`LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS`\n",
    "<br/>\n",
    "\n",
    "Now let's add the top 12-22 stocks (as of end-April 2024):\n",
    "<br/>\n",
    "\n",
    "`NEW_US = ['TSLA','WMT','XOM','UNH','MA','PG','JNJ','MRK','HD','COST','ORCL']`\n",
    "\n",
    "`NEW_EU = ['PRX.AS','CDI.PA','AIR.PA','SU.PA','ETN','SNY','BUD','DTE.DE','ALV.DE','MDT','AI.PA','EL.PA']`\n",
    "\n",
    "`NEW_INDIA = ['BAJFINANCE.NS','MARUTI.NS','HCLTECH.NS','TATAMOTORS.NS','SUNPHARMA.NS','ONGC.NS','ADANIENT.NS','ADANIENT.NS','NTPC.NS','KOTAKBANK.NS','TITAN.NS']`\n",
    "\n",
    "`LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA`\n",
    "\n",
    "You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS.\n",
    "\n",
    "Calculate  `growth_7d` for every stock and every day.\n",
    "Get the average daily `growth_7d` for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "For example, for the first of data you should have:\n",
    "| Date   |      ticker_category      |  growth_7d |\n",
    "|----------|:-------------:|------:|\n",
    "| 2014-01-01 |  LARGE | 1.011684 |\n",
    "| 2014-01-01 |   LARGEST   |   1.011797 |\n",
    "\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
<<<<<<< HEAD
<<<<<<< HEAD
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n",
    "\n",
    "---\n",
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw02\n",
    "\n",
    "-"
   ]
>>>>>>> c20d40f (Add response to first question)
=======
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LLY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AVGO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MC.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ASML...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RMS.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for OR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ACN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SIE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IDEXY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RELIANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TCS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BHARTIARTL.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IBN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBIN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LICI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INFY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ITC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HINDUNILVR.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PRX.AS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n",
      "Fetching data for AIR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SU.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BUD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DTE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALV.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MDT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EL.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ORCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BAJFINANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MARUTI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCLTECH.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TATAMOTORS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SUNPHARMA.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ONGC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n",
      "Fetching data for NTPC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KOTAKBANK.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TITAN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks retrieved for LARGEST_STOCKS: 33\n",
      "Number of stocks retrieved for LARGE_STOCKS: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the list of ticker symbols for each group of stocks\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
    "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
    "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS', 'HINDUNILVR.NS', 'LT.NS']\n",
    "LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
    "NEW_EU = ['PRX.AS', 'CDI.PA', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
    "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS', 'ADANIENT.NS', 'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
    "LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA\n",
    "\n",
    "# Function to fetch OHLCV data for a given list of tickers and date range\n",
    "def fetch_ohlcv_data(tickers, start_date, end_date):\n",
    "    ohlcvs = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                ohlcvs[ticker] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return ohlcvs\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch OHLCV data for the LARGEST_STOCKS\n",
    "ohlcvs_largest = fetch_ohlcv_data(LARGEST_STOCKS, start_date, end_date)\n",
    "\n",
    "# Fetch OHLCV data for the LARGE_STOCKS\n",
    "ohlcvs_large = fetch_ohlcv_data(LARGE_STOCKS, start_date, end_date)\n",
    "\n",
    "# Display the number of stocks retrieved for each group\n",
    "print(f\"Number of stocks retrieved for LARGEST_STOCKS: {len(ohlcvs_largest)}\")\n",
    "print(f\"Number of stocks retrieved for LARGE_STOCKS: {len(ohlcvs_large)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Growth (LARGEST_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.013788\n",
      "2023-12-26    0.014900\n",
      "2023-12-27    0.014155\n",
      "2023-12-28    0.008533\n",
      "2023-12-29    0.005337\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n",
      "\n",
      "Average Daily Growth (LARGE_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.003809\n",
      "2023-12-26    0.014441\n",
      "2023-12-27    0.003737\n",
      "2023-12-28    0.000275\n",
      "2023-12-29    0.000244\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate 7-day growth\n",
    "def calculate_growth_7d(df):\n",
    "    df['growth_7d'] = df['Adj Close'].pct_change(periods=7)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGEST_STOCKS\n",
    "for ticker, df in ohlcvs_largest.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGE_STOCKS\n",
    "for ticker, df in ohlcvs_large.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Combine OHLCV data for LARGEST_STOCKS into a single DataFrame\n",
    "largest_df = pd.concat(ohlcvs_largest.values())\n",
    "\n",
    "# Combine OHLCV data for LARGE_STOCKS into a single DataFrame\n",
    "large_df = pd.concat(ohlcvs_large.values())\n",
    "\n",
    "# Calculate average daily growth_7d for LARGEST_STOCKS\n",
    "avg_growth_7d_largest = largest_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Calculate average daily growth_7d for LARGE_STOCKS\n",
    "avg_growth_7d_large = large_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Display the average daily growth_7d for both groups\n",
    "print(\"Average Daily Growth (LARGEST_STOCKS):\")\n",
    "print(avg_growth_7d_largest)\n",
    "print(\"\\nAverage Daily Growth (LARGE_STOCKS):\")\n",
    "print(avg_growth_7d_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of days when LARGE stocks outperform LARGEST stocks: 47 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "num_days_outperform = (avg_growth_7d_large > avg_growth_7d_largest).sum()\n",
    "\n",
    "# Calculate the percentage of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "percentage_outperform = (num_days_outperform / 2595) * 100\n",
    "\n",
    "# Convert to the closest integer value\n",
    "percentage_outperform = round(percentage_outperform)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of days when LARGE stocks outperform LARGEST stocks:\", percentage_outperform, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Trying Another Technical Indicators strategy\n",
    "\n",
    "**What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?**\n",
    "\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31).\n",
    "If you encounter any difficulties running the Colab - you can download it using this [link](https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing).\n",
    "\n",
    "Let's assume you've learned about the awesome **CCI indicator** ([Commodity Channel Index](https://www.investopedia.com/terms/c/commoditychannelindex.asp)), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (`Date.dt.dayofweek()==4`).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years?\n",
    "One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit.\n",
    "You need to sum these results over all trades (460 times in 10 years).\n",
    "\n",
    "Additional:\n",
    "  * Add an approximate fees calculation over the 460 trades from this calculator https://www.degiro.ie/fees/calculator (Product:\"Shares, USA and Canada;\" Amount per transaction: \"1000 EUR\"; Transactions per year: \"460\")\n",
    "  * are you still profitable on those trades?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('stocks_df_combined_2024_05_06.parquet.brotli', engine='pyarrow')"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('stocks_df_combined_2024_05_06.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_colab = pd.read_parquet('stocks_df_combined_trunc_2014_2023.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close_x',\n",
       " 'Volume',\n",
       " 'Ticker',\n",
       " 'Year',\n",
       " 'Month',\n",
       " 'Weekday',\n",
       " 'Date',\n",
       " 'growth_1d',\n",
       " 'growth_3d',\n",
       " 'growth_7d',\n",
       " 'growth_30d',\n",
       " 'growth_90d',\n",
       " 'growth_365d',\n",
       " 'growth_future_5d',\n",
       " 'SMA10',\n",
       " 'SMA20',\n",
       " 'growing_moving_average',\n",
       " 'high_minus_low_relative',\n",
       " 'volatility',\n",
       " 'is_positive_growth_5d_future',\n",
       " 'ticker_type',\n",
       " 'index_x',\n",
       " 'adx',\n",
       " 'adxr',\n",
       " 'apo',\n",
       " 'aroon_1',\n",
       " 'aroon_2',\n",
       " 'aroonosc',\n",
       " 'bop',\n",
       " 'cci',\n",
       " 'cmo',\n",
       " 'dx',\n",
       " 'macd',\n",
       " 'macdsignal',\n",
       " 'macdhist',\n",
       " 'macd_ext',\n",
       " 'macdsignal_ext',\n",
       " 'macdhist_ext',\n",
       " 'macd_fix',\n",
       " 'macdsignal_fix',\n",
       " 'macdhist_fix',\n",
       " 'mfi',\n",
       " 'minus_di',\n",
       " 'mom',\n",
       " 'plus_di',\n",
       " 'dm',\n",
       " 'ppo',\n",
       " 'roc',\n",
       " 'rocp',\n",
       " 'rocr',\n",
       " 'rocr100',\n",
       " 'rsi',\n",
       " 'slowk',\n",
       " 'slowd',\n",
       " 'fastk',\n",
       " 'fastd',\n",
       " 'fastk_rsi',\n",
       " 'fastd_rsi',\n",
       " 'trix',\n",
       " 'ultosc',\n",
       " 'willr',\n",
       " 'index_y',\n",
       " 'ad',\n",
       " 'adosc',\n",
       " 'obv',\n",
       " 'atr',\n",
       " 'natr',\n",
       " 'ht_dcperiod',\n",
       " 'ht_dcphase',\n",
       " 'ht_phasor_inphase',\n",
       " 'ht_phasor_quadrature',\n",
       " 'ht_sine_sine',\n",
       " 'ht_sine_leadsine',\n",
       " 'ht_trendmod',\n",
       " 'avgprice',\n",
       " 'medprice',\n",
       " 'typprice',\n",
       " 'wclprice',\n",
       " 'index',\n",
       " 'cdl2crows',\n",
       " 'cdl3blackrows',\n",
       " 'cdl3inside',\n",
       " 'cdl3linestrike',\n",
       " 'cdl3outside',\n",
       " 'cdl3starsinsouth',\n",
       " 'cdl3whitesoldiers',\n",
       " 'cdlabandonedbaby',\n",
       " 'cdladvancedblock',\n",
       " 'cdlbelthold',\n",
       " 'cdlbreakaway',\n",
       " 'cdlclosingmarubozu',\n",
       " 'cdlconcealbabyswall',\n",
       " 'cdlcounterattack',\n",
       " 'cdldarkcloudcover',\n",
       " 'cdldoji',\n",
       " 'cdldojistar',\n",
       " 'cdldragonflydoji',\n",
       " 'cdlengulfing',\n",
       " 'cdleveningdojistar',\n",
       " 'cdleveningstar',\n",
       " 'cdlgapsidesidewhite',\n",
       " 'cdlgravestonedoji',\n",
       " 'cdlhammer',\n",
       " 'cdlhangingman',\n",
       " 'cdlharami',\n",
       " 'cdlharamicross',\n",
       " 'cdlhighwave',\n",
       " 'cdlhikkake',\n",
       " 'cdlhikkakemod',\n",
       " 'cdlhomingpigeon',\n",
       " 'cdlidentical3crows',\n",
       " 'cdlinneck',\n",
       " 'cdlinvertedhammer',\n",
       " 'cdlkicking',\n",
       " 'cdlkickingbylength',\n",
       " 'cdlladderbottom',\n",
       " 'cdllongleggeddoji',\n",
       " 'cdllongline',\n",
       " 'cdlmarubozu',\n",
       " 'cdlmatchinglow',\n",
       " 'cdlmathold',\n",
       " 'cdlmorningdojistar',\n",
       " 'cdlmorningstar',\n",
       " 'cdlonneck',\n",
       " 'cdlpiercing',\n",
       " 'cdlrickshawman',\n",
       " 'cdlrisefall3methods',\n",
       " 'cdlseparatinglines',\n",
       " 'cdlshootingstar',\n",
       " 'cdlshortline',\n",
       " 'cdlspinningtop',\n",
       " 'cdlstalledpattern',\n",
       " 'cdlsticksandwich',\n",
       " 'cdltakuru',\n",
       " 'cdltasukigap',\n",
       " 'cdlthrusting',\n",
       " 'cdltristar',\n",
       " 'cdlunique3river',\n",
       " 'cdlupsidegap2crows',\n",
       " 'cdlxsidegap3methods',\n",
       " 'growth_dax_1d',\n",
       " 'growth_dax_3d',\n",
       " 'growth_dax_7d',\n",
       " 'growth_dax_30d',\n",
       " 'growth_dax_90d',\n",
       " 'growth_dax_365d',\n",
       " 'growth_snp500_1d',\n",
       " 'growth_snp500_3d',\n",
       " 'growth_snp500_7d',\n",
       " 'growth_snp500_30d',\n",
       " 'growth_snp500_90d',\n",
       " 'growth_snp500_365d',\n",
       " 'growth_dji_1d',\n",
       " 'growth_dji_3d',\n",
       " 'growth_dji_7d',\n",
       " 'growth_dji_30d',\n",
       " 'growth_dji_90d',\n",
       " 'growth_dji_365d',\n",
       " 'growth_epi_1d',\n",
       " 'growth_epi_3d',\n",
       " 'growth_epi_7d',\n",
       " 'growth_epi_30d',\n",
       " 'growth_epi_90d',\n",
       " 'growth_epi_365d',\n",
       " 'Quarter',\n",
       " 'gdppot_us_yoy',\n",
       " 'gdppot_us_qoq',\n",
       " 'cpi_core_yoy',\n",
       " 'cpi_core_mom',\n",
       " 'FEDFUNDS',\n",
       " 'DGS1',\n",
       " 'DGS5',\n",
       " 'DGS10',\n",
       " 'Adj Close_y',\n",
       " 'growth_gold_1d',\n",
       " 'growth_gold_3d',\n",
       " 'growth_gold_7d',\n",
       " 'growth_gold_30d',\n",
       " 'growth_gold_90d',\n",
       " 'growth_gold_365d',\n",
       " 'growth_wti_oil_1d',\n",
       " 'growth_wti_oil_3d',\n",
       " 'growth_wti_oil_7d',\n",
       " 'growth_wti_oil_30d',\n",
       " 'growth_wti_oil_90d',\n",
       " 'growth_wti_oil_365d',\n",
       " 'growth_brent_oil_1d',\n",
       " 'growth_brent_oil_3d',\n",
       " 'growth_brent_oil_7d',\n",
       " 'growth_brent_oil_30d',\n",
       " 'growth_brent_oil_90d',\n",
       " 'growth_brent_oil_365d',\n",
       " 'growth_btc_usd_1d',\n",
       " 'growth_btc_usd_3d',\n",
       " 'growth_btc_usd_7d',\n",
       " 'growth_btc_usd_30d',\n",
       " 'growth_btc_usd_90d',\n",
       " 'growth_btc_usd_365d']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(full_df_colab.columns)"
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
>>>>>>> f71084a (Trying to solve question 4 but not yet)
=======
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 221109 entries, 0 to 5425\n",
      "Columns: 202 entries, Open to growth_btc_usd_365d\n",
      "dtypes: datetime64[ns](3), float64(128), int32(66), int64(3), object(2)\n",
      "memory usage: 286.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-13</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-14</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-17</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-18</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-19</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month       Date    Quarter\n",
       "0    1986-03-01 1986-03-13 1986-01-01\n",
       "1    1986-03-01 1986-03-14 1986-01-01\n",
       "2    1986-03-01 1986-03-17 1986-01-01\n",
       "3    1986-03-01 1986-03-18 1986-01-01\n",
       "4    1986-03-01 1986-03-19 1986-01-01\n",
       "...         ...        ...        ...\n",
       "5421 2024-04-01 2024-04-29 2024-04-01\n",
       "5422 2024-04-01 2024-04-30 2024-04-01\n",
       "5423 2024-05-01 2024-05-02 2024-04-01\n",
       "5424 2024-05-01 2024-05-03 2024-04-01\n",
       "5425 2024-05-01 2024-05-06 2024-04-01\n",
       "\n",
       "[221109 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.select_dtypes(include='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['TP'] = (full_df['High'] + full_df['Low'] + full_df['Close']) / 3\n",
    "full_df['SMA'] = full_df['TP'].rolling(window=20).mean()\n",
    "full_df['CCI'] = (full_df['TP'] - full_df['SMA']) / ( 0.015 * full_df['TP'].rolling(window=20).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "      <th>TP</th>\n",
       "      <th>SMA</th>\n",
       "      <th>CCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>3606.100098</td>\n",
       "      <td>3649.899902</td>\n",
       "      <td>3605.199951</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>1.396979e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>1.011533</td>\n",
       "      <td>1.001346</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.916661</td>\n",
       "      <td>1.486315</td>\n",
       "      <td>2.181200</td>\n",
       "      <td>3629.799967</td>\n",
       "      <td>3688.120833</td>\n",
       "      <td>-39.282699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1.571996e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.850046</td>\n",
       "      <td>1.423982</td>\n",
       "      <td>2.158543</td>\n",
       "      <td>3609.100016</td>\n",
       "      <td>3680.662500</td>\n",
       "      <td>-48.174406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3.748847e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931945</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.926103</td>\n",
       "      <td>0.916902</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>1.369046</td>\n",
       "      <td>2.038296</td>\n",
       "      <td>3603.233317</td>\n",
       "      <td>3669.645829</td>\n",
       "      <td>-46.877716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4.079696e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946816</td>\n",
       "      <td>1.063704</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>1.462818</td>\n",
       "      <td>2.180063</td>\n",
       "      <td>3536.750000</td>\n",
       "      <td>3655.839164</td>\n",
       "      <td>-85.763917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2.614667e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3477.133382</td>\n",
       "      <td>3640.490837</td>\n",
       "      <td>-113.935329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "0        0.088542     0.101563     0.088542     0.097222     0.060163   \n",
       "1        0.097222     0.102431     0.097222     0.100694     0.062311   \n",
       "2        0.100694     0.103299     0.100694     0.102431     0.063386   \n",
       "3        0.102431     0.103299     0.098958     0.099826     0.061774   \n",
       "4        0.099826     0.100694     0.097222     0.098090     0.060700   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5421  3606.100098  3649.899902  3605.199951  3634.300049  3634.300049   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "\n",
       "            Volume Ticker  Year      Month  Weekday  ...  \\\n",
       "0     1.031789e+09   MSFT  1986 1986-03-01        3  ...   \n",
       "1     3.081600e+08   MSFT  1986 1986-03-01        4  ...   \n",
       "2     1.331712e+08   MSFT  1986 1986-03-01        0  ...   \n",
       "3     6.776640e+07   MSFT  1986 1986-03-01        1  ...   \n",
       "4     4.789440e+07   MSFT  1986 1986-03-01        2  ...   \n",
       "...            ...    ...   ...        ...      ...  ...   \n",
       "5421  1.396979e+06  LT.NS  2024 2024-04-01        0  ...   \n",
       "5422  1.571996e+06  LT.NS  2024 2024-04-01        1  ...   \n",
       "5423  3.748847e+06  LT.NS  2024 2024-05-01        3  ...   \n",
       "5424  4.079696e+06  LT.NS  2024 2024-05-01        4  ...   \n",
       "5425  2.614667e+06  LT.NS  2024 2024-05-01        0  ...   \n",
       "\n",
       "     growth_brent_oil_365d  growth_btc_usd_1d  growth_btc_usd_3d  \\\n",
       "0                      NaN                NaN                NaN   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                      NaN                NaN                NaN   \n",
       "3                      NaN                NaN                NaN   \n",
       "4                      NaN                NaN                NaN   \n",
       "...                    ...                ...                ...   \n",
       "5421              0.949109           1.011533           1.001346   \n",
       "5422              0.936075           0.949809           0.956129   \n",
       "5423              0.931945           1.014925           0.926103   \n",
       "5424              0.946816           1.063704           1.037155   \n",
       "5425              0.954603                NaN                NaN   \n",
       "\n",
       "      growth_btc_usd_7d  growth_btc_usd_30d  growth_btc_usd_90d  \\\n",
       "0                   NaN                 NaN                 NaN   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "2                   NaN                 NaN                 NaN   \n",
       "3                   NaN                 NaN                 NaN   \n",
       "4                   NaN                 NaN                 NaN   \n",
       "...                 ...                 ...                 ...   \n",
       "5421           0.955167            0.916661            1.486315   \n",
       "5422           0.913106            0.850046            1.423982   \n",
       "5423           0.916902            0.903379            1.369046   \n",
       "5424           0.986425            0.953153            1.462818   \n",
       "5425                NaN                 NaN                 NaN   \n",
       "\n",
       "      growth_btc_usd_365d           TP          SMA         CCI  \n",
       "0                     NaN     0.095776          NaN         NaN  \n",
       "1                     NaN     0.100116          NaN         NaN  \n",
       "2                     NaN     0.102141          NaN         NaN  \n",
       "3                     NaN     0.100694          NaN         NaN  \n",
       "4                     NaN     0.098669          NaN         NaN  \n",
       "...                   ...          ...          ...         ...  \n",
       "5421             2.181200  3629.799967  3688.120833  -39.282699  \n",
       "5422             2.158543  3609.100016  3680.662500  -48.174406  \n",
       "5423             2.038296  3603.233317  3669.645829  -46.877716  \n",
       "5424             2.180063  3536.750000  3655.839164  -85.763917  \n",
       "5425                  NaN  3477.133382  3640.490837 -113.935329  \n",
       "\n",
       "[221109 rows x 205 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close_x', 'Volume', 'Ticker',\n",
       "       'Year', 'Month', 'Weekday',\n",
       "       ...\n",
       "       'growth_brent_oil_365d', 'growth_btc_usd_1d', 'growth_btc_usd_3d',\n",
       "       'growth_btc_usd_7d', 'growth_btc_usd_30d', 'growth_btc_usd_90d',\n",
       "       'growth_btc_usd_365d', 'TP', 'SMA', 'CCI'],\n",
       "      dtype='object', length=205)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_trades = full_df[(full_df['Date'].dt.dayofweek == 4) & (full_df['CCI'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>40.450001</td>\n",
       "      <td>40.970001</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>40.939999</td>\n",
       "      <td>34.912762</td>\n",
       "      <td>34567600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997447</td>\n",
       "      <td>1.005607</td>\n",
       "      <td>1.021664</td>\n",
       "      <td>0.995813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.910000</td>\n",
       "      <td>39.395618</td>\n",
       "      <td>36939400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983610</td>\n",
       "      <td>0.941627</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>45.660000</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>41.630741</td>\n",
       "      <td>130933700.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1.143658</td>\n",
       "      <td>1.055457</td>\n",
       "      <td>0.614516</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>1.037625</td>\n",
       "      <td>0.939362</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>44.270000</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>40.151123</td>\n",
       "      <td>41839000.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007958</td>\n",
       "      <td>1.032390</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>1.002560</td>\n",
       "      <td>1.009139</td>\n",
       "      <td>1.034930</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.632660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>52.299999</td>\n",
       "      <td>54.070000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>46.583046</td>\n",
       "      <td>135227100.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976399</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.751370</td>\n",
       "      <td>0.435520</td>\n",
       "      <td>1.009025</td>\n",
       "      <td>1.026100</td>\n",
       "      <td>1.051840</td>\n",
       "      <td>1.200679</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.771437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>2061.000000</td>\n",
       "      <td>2095.800049</td>\n",
       "      <td>2058.449951</td>\n",
       "      <td>2062.750000</td>\n",
       "      <td>2058.108887</td>\n",
       "      <td>2652761.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891008</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>1.124210</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.020511</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.795450</td>\n",
       "      <td>0.824372</td>\n",
       "      <td>0.288467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2483.500000</td>\n",
       "      <td>2415.050049</td>\n",
       "      <td>2475.550049</td>\n",
       "      <td>2469.979980</td>\n",
       "      <td>2690699.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971214</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.901866</td>\n",
       "      <td>0.870323</td>\n",
       "      <td>1.001048</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>1.119678</td>\n",
       "      <td>1.072726</td>\n",
       "      <td>1.540443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2521.100098</td>\n",
       "      <td>2586.250000</td>\n",
       "      <td>2580.430908</td>\n",
       "      <td>4610417.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011984</td>\n",
       "      <td>1.053541</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>0.869197</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>1.075177</td>\n",
       "      <td>1.291138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2928.699951</td>\n",
       "      <td>2872.449951</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>3638510.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060358</td>\n",
       "      <td>1.076092</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.751347</td>\n",
       "      <td>0.987251</td>\n",
       "      <td>1.004875</td>\n",
       "      <td>1.004067</td>\n",
       "      <td>0.876331</td>\n",
       "      <td>1.002105</td>\n",
       "      <td>1.340190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>3129.949951</td>\n",
       "      <td>3197.949951</td>\n",
       "      <td>3121.050049</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>2112908.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962421</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.936372</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>1.025880</td>\n",
       "      <td>1.022671</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>1.091754</td>\n",
       "      <td>1.495576</td>\n",
       "      <td>2.280217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "7113    40.450001    40.970001    40.250000    40.939999    34.912762   \n",
       "7181    45.110001    45.930000    45.110001    45.910000    39.395618   \n",
       "7340    45.660000    48.139999    45.650002    47.869999    41.630741   \n",
       "7452    44.270000    45.570000    43.919998    45.570000    40.151123   \n",
       "7467    52.299999    54.070000    52.250000    52.869999    46.583046   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5072  2061.000000  2095.800049  2058.449951  2062.750000  2058.108887   \n",
       "5219  2420.000000  2483.500000  2415.050049  2475.550049  2469.979980   \n",
       "5234  2522.000000  2595.000000  2521.100098  2586.250000  2580.430908   \n",
       "5268  2888.000000  2928.699951  2872.449951  2901.600098  2901.600098   \n",
       "5323  3129.949951  3197.949951  3121.050049  3190.649902  3190.649902   \n",
       "\n",
       "           Volume Ticker  Year      Month  Weekday  ... growth_brent_oil_7d  \\\n",
       "7113   34567600.0   MSFT  2014 2014-05-01        4  ...            0.997447   \n",
       "7181   36939400.0   MSFT  2014 2014-09-01        4  ...            0.983610   \n",
       "7340  130933700.0   MSFT  2015 2015-04-01        4  ...            1.082228   \n",
       "7452   41839000.0   MSFT  2015 2015-10-01        4  ...            1.007958   \n",
       "7467  135227100.0   MSFT  2015 2015-10-01        4  ...            0.976399   \n",
       "...           ...    ...   ...        ...      ...  ...                 ...   \n",
       "5072    2652761.0  LT.NS  2022 2022-11-01        4  ...            0.891008   \n",
       "5219    2690699.0  LT.NS  2023 2023-06-01        4  ...            0.971214   \n",
       "5234    4610417.0  LT.NS  2023 2023-07-01        4  ...            1.011984   \n",
       "5268    3638510.0  LT.NS  2023 2023-09-01        4  ...            1.060358   \n",
       "5323    2112908.0  LT.NS  2023 2023-12-01        4  ...            0.962421   \n",
       "\n",
       "      growth_brent_oil_30d  growth_brent_oil_90d  growth_brent_oil_365d  \\\n",
       "7113              1.005607              1.021664               0.995813   \n",
       "7181              0.941627              0.925124               0.914716   \n",
       "7340              1.143658              1.055457               0.614516   \n",
       "7452              1.032390              0.775540               0.441114   \n",
       "7467              0.996884              0.751370               0.435520   \n",
       "...                    ...                   ...                    ...   \n",
       "5072              0.884318              0.782174               1.124210   \n",
       "5219              0.973233              0.901866               0.870323   \n",
       "5234              1.053541              1.003714               0.869197   \n",
       "5268              1.076092              1.142983               0.751347   \n",
       "5323              0.855903              0.936372               0.705924   \n",
       "\n",
       "      growth_btc_usd_1d  growth_btc_usd_3d  growth_btc_usd_7d  \\\n",
       "7113                NaN                NaN                NaN   \n",
       "7181                NaN                NaN                NaN   \n",
       "7340           0.978035           0.982994           1.037625   \n",
       "7452           0.998922           1.002560           1.009139   \n",
       "7467           1.009025           1.026100           1.051840   \n",
       "...                 ...                ...                ...   \n",
       "5072           0.995024           1.020511           0.989464   \n",
       "5219           1.001048           0.993127           0.992891   \n",
       "5234           1.003918           1.001748           0.985979   \n",
       "5268           0.987251           1.004875           1.004067   \n",
       "5323           1.025880           1.022671           1.025675   \n",
       "\n",
       "      growth_btc_usd_30d  growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "7113                 NaN                 NaN                  NaN  \n",
       "7181                 NaN                 NaN                  NaN  \n",
       "7340            0.939362            0.933108                  NaN  \n",
       "7452            1.034930            0.909566             0.632660  \n",
       "7467            1.200679            0.957738             0.771437  \n",
       "...                  ...                 ...                  ...  \n",
       "5072            0.795450            0.824372             0.288467  \n",
       "5219            1.119678            1.072726             1.540443  \n",
       "5234            0.996052            1.075177             1.291138  \n",
       "5268            0.876331            1.002105             1.340190  \n",
       "5323            1.091754            1.495576             2.280217  \n",
       "\n",
       "[460 rows x 202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades_colab = full_df_colab[(full_df_colab['Date'].dt.dayofweek == 4) & (full_df_colab['cci']>200)]\n",
    "qualifying_trades_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-04-27 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1986-04-30 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected gross profit (in thousands of dollars): -7\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to store gross profit\n",
    "gross_profit = 0\n",
    "\n",
    "# Iterate through each qualifying trade\n",
    "for index,row in qualifying_trades.iterrows():\n",
    "    # Calculate the buy price (Adj. Close price)\n",
    "    buy_price = row['Adj Close_x']\n",
    "    #print(buy_price, 'buy')\n",
    "    # Try to find the sell price after 5 trading days\n",
    "    try:\n",
    "        sell_price = full_df_colab.loc[(full_df_colab['Date']==full_df_colab.iloc[index]['Date'] + pd.Timedelta(days=5))  & (full_df_colab['Ticker']==row['Ticker'])]['growth_future_5d'].iloc[0]\n",
    "        #print(sell_price, 'sell')\n",
    "    except KeyError and IndexError:\n",
    "        # If there are not enough trading days in the future, skip this trade\n",
    "        continue\n",
    "    \n",
    "    # Calculate the profit or loss from this trade\n",
    "    trade_profit = (sell_price - buy_price) * (1000 / buy_price)\n",
    "    #print(trade_profit, 'profit')\n",
    "    gross_profit += trade_profit\n",
    "\n",
    "# Convert the gross profit to thousands of dollars and round to the nearest integer\n",
    "gross_profit_thousands = round(gross_profit/1000)\n",
    "\n",
    "# Display the expected gross profit\n",
    "print(\"Expected gross profit (in thousands of dollars):\", gross_profit_thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, I would try to make the scope smaller. Look for growth and performance in several industries. Other step would be probably to read news about how is the market demand and the sentiment in general for those IPO. Finally, is not a bad idea on check for experts opinions. \n",
    "I think the best way to analyse an IPO is to make a smart comparison against existing stocks. "
   ]
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
<<<<<<< HEAD
>>>>>>> 2eed79c (Done with the questions for the homework2)
=======
=======
=======
=======
>>>>>>> 4ce4663 (almost add question 2 response)
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Is Growth Concentrated in the Largest Stocks?\n",
    "\n",
    "**Get the share of days (percentage as int) when Large Stocks outperform (growth_7d - growth over 7 periods back) the Largest stocks?**\n",
    "\n",
    "\n",
    "Reuse [Code Snippet 5] to obtain OHLCV stats for 33 stocks \n",
    "for 10 full years of data (2014-01-01 to 2023-12-31):\n",
    "\n",
    "`US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO','V', 'JPM']`\n",
    "\n",
    "`EU_STOCKS = ['NVO','MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE','IDEXY','CDI.PA']`\n",
    "\n",
    "`INDIA_STOCKS = ['RELIANCE.NS','TCS.NS','HDB','BHARTIARTL.NS','IBN','SBIN.NS','LICI.NS','INFY','ITC.NS','HINDUNILVR.NS','LT.NS']`\n",
    "\n",
    "`LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS`\n",
    "<br/>\n",
    "\n",
    "Now let's add the top 12-22 stocks (as of end-April 2024):\n",
    "<br/>\n",
    "\n",
    "`NEW_US = ['TSLA','WMT','XOM','UNH','MA','PG','JNJ','MRK','HD','COST','ORCL']`\n",
    "\n",
    "`NEW_EU = ['PRX.AS','CDI.PA','AIR.PA','SU.PA','ETN','SNY','BUD','DTE.DE','ALV.DE','MDT','AI.PA','EL.PA']`\n",
    "\n",
    "`NEW_INDIA = ['BAJFINANCE.NS','MARUTI.NS','HCLTECH.NS','TATAMOTORS.NS','SUNPHARMA.NS','ONGC.NS','ADANIENT.NS','ADANIENT.NS','NTPC.NS','KOTAKBANK.NS','TITAN.NS']`\n",
    "\n",
    "`LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA`\n",
    "\n",
    "You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS.\n",
    "\n",
    "Calculate  `growth_7d` for every stock and every day.\n",
    "Get the average daily `growth_7d` for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "For example, for the first of data you should have:\n",
    "| Date   |      ticker_category      |  growth_7d |\n",
<<<<<<< HEAD
    "|----------|:-------------:|------:|\n",
    "| 2014-01-01 |  LARGE | 1.011684 |\n",
    "| 2014-01-01 |   LARGEST   |   1.011797 |\n",
    "\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Trying Another Technical Indicators strategy\n",
    "\n",
    "**What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?**\n",
    "\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31).\n",
    "If you encounter any difficulties running the Colab - you can download it using this [link](https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing).\n",
    "\n",
    "Let's assume you've learned about the awesome **CCI indicator** ([Commodity Channel Index](https://www.investopedia.com/terms/c/commoditychannelindex.asp)), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (`Date.dt.dayofweek()==4`).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years?\n",
    "One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit.\n",
    "You need to sum these results over all trades (460 times in 10 years).\n",
    "\n",
    "Additional:\n",
    "  * Add an approximate fees calculation over the 460 trades from this calculator https://www.degiro.ie/fees/calculator (Product:\"Shares, USA and Canada;\" Amount per transaction: \"1000 EUR\"; Transactions per year: \"460\")\n",
    "  * are you still profitable on those trades?\n",
    "\n",
=======
    "|----------|:-------------:|------:|\n",
    "| 2014-01-01 |  LARGE | 1.011684 |\n",
    "| 2014-01-01 |   LARGEST   |   1.011797 |\n",
    "\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
    "\n",
    "---"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
=======
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
<<<<<<< HEAD
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n",
    "\n",
    "---\n",
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw02\n",
    "\n",
    "-"
   ]
>>>>>>> a1fa175 (Add response to first question)
=======
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
=======
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LLY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AVGO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MC.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ASML...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RMS.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for OR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ACN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SIE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IDEXY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RELIANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TCS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BHARTIARTL.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IBN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBIN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LICI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INFY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ITC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HINDUNILVR.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PRX.AS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CDI.PA...\n",
      "Fetching data for AIR.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SU.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BUD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DTE.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALV.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MDT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EL.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ORCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BAJFINANCE.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MARUTI.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCLTECH.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TATAMOTORS.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SUNPHARMA.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ONGC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ADANIENT.NS...\n",
      "Fetching data for NTPC.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KOTAKBANK.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TITAN.NS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks retrieved for LARGEST_STOCKS: 33\n",
      "Number of stocks retrieved for LARGE_STOCKS: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the list of ticker symbols for each group of stocks\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
    "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
    "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS', 'HINDUNILVR.NS', 'LT.NS']\n",
    "LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
    "NEW_EU = ['PRX.AS', 'CDI.PA', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
    "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS', 'ADANIENT.NS', 'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
    "LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA\n",
    "\n",
    "# Function to fetch OHLCV data for a given list of tickers and date range\n",
    "def fetch_ohlcv_data(tickers, start_date, end_date):\n",
    "    ohlcvs = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                ohlcvs[ticker] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return ohlcvs\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch OHLCV data for the LARGEST_STOCKS\n",
    "ohlcvs_largest = fetch_ohlcv_data(LARGEST_STOCKS, start_date, end_date)\n",
    "\n",
    "# Fetch OHLCV data for the LARGE_STOCKS\n",
    "ohlcvs_large = fetch_ohlcv_data(LARGE_STOCKS, start_date, end_date)\n",
    "\n",
    "# Display the number of stocks retrieved for each group\n",
    "print(f\"Number of stocks retrieved for LARGEST_STOCKS: {len(ohlcvs_largest)}\")\n",
    "print(f\"Number of stocks retrieved for LARGE_STOCKS: {len(ohlcvs_large)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Growth (LARGEST_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.013788\n",
      "2023-12-26    0.014900\n",
      "2023-12-27    0.014155\n",
      "2023-12-28    0.008533\n",
      "2023-12-29    0.005337\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n",
      "\n",
      "Average Daily Growth (LARGE_STOCKS):\n",
      "Date\n",
      "2014-01-01         NaN\n",
      "2014-01-02         NaN\n",
      "2014-01-03         NaN\n",
      "2014-01-06         NaN\n",
      "2014-01-07         NaN\n",
      "                ...   \n",
      "2023-12-22    0.003809\n",
      "2023-12-26    0.014441\n",
      "2023-12-27    0.003737\n",
      "2023-12-28    0.000275\n",
      "2023-12-29    0.000244\n",
      "Name: growth_7d, Length: 2595, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate 7-day growth\n",
    "def calculate_growth_7d(df):\n",
    "    df['growth_7d'] = df['Adj Close'].pct_change(periods=7)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGEST_STOCKS\n",
    "for ticker, df in ohlcvs_largest.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Calculate growth_7d for each stock in LARGE_STOCKS\n",
    "for ticker, df in ohlcvs_large.items():\n",
    "    calculate_growth_7d(df)\n",
    "\n",
    "# Combine OHLCV data for LARGEST_STOCKS into a single DataFrame\n",
    "largest_df = pd.concat(ohlcvs_largest.values())\n",
    "\n",
    "# Combine OHLCV data for LARGE_STOCKS into a single DataFrame\n",
    "large_df = pd.concat(ohlcvs_large.values())\n",
    "\n",
    "# Calculate average daily growth_7d for LARGEST_STOCKS\n",
    "avg_growth_7d_largest = largest_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Calculate average daily growth_7d for LARGE_STOCKS\n",
    "avg_growth_7d_large = large_df.groupby(level=0)['growth_7d'].mean()\n",
    "\n",
    "# Display the average daily growth_7d for both groups\n",
    "print(\"Average Daily Growth (LARGEST_STOCKS):\")\n",
    "print(avg_growth_7d_largest)\n",
    "print(\"\\nAverage Daily Growth (LARGE_STOCKS):\")\n",
    "print(avg_growth_7d_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of days when LARGE stocks outperform LARGEST stocks: 47 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "num_days_outperform = (avg_growth_7d_large > avg_growth_7d_largest).sum()\n",
    "\n",
    "# Calculate the percentage of days when the LARGE GROUP outperforms the LARGEST GROUP\n",
    "percentage_outperform = (num_days_outperform / 2595) * 100\n",
    "\n",
    "# Convert to the closest integer value\n",
    "percentage_outperform = round(percentage_outperform)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of days when LARGE stocks outperform LARGEST stocks:\", percentage_outperform, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Trying Another Technical Indicators strategy\n",
    "\n",
    "**What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?**\n",
    "\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31).\n",
    "If you encounter any difficulties running the Colab - you can download it using this [link](https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing).\n",
    "\n",
    "Let's assume you've learned about the awesome **CCI indicator** ([Commodity Channel Index](https://www.investopedia.com/terms/c/commoditychannelindex.asp)), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (`Date.dt.dayofweek()==4`).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years?\n",
    "One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit.\n",
    "You need to sum these results over all trades (460 times in 10 years).\n",
    "\n",
    "Additional:\n",
    "  * Add an approximate fees calculation over the 460 trades from this calculator https://www.degiro.ie/fees/calculator (Product:\"Shares, USA and Canada;\" Amount per transaction: \"1000 EUR\"; Transactions per year: \"460\")\n",
    "  * are you still profitable on those trades?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet('stocks_df_combined_2024_05_06.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_colab = pd.read_parquet('stocks_df_combined_trunc_2014_2023.parquet.brotli', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close_x',\n",
       " 'Volume',\n",
       " 'Ticker',\n",
       " 'Year',\n",
       " 'Month',\n",
       " 'Weekday',\n",
       " 'Date',\n",
       " 'growth_1d',\n",
       " 'growth_3d',\n",
       " 'growth_7d',\n",
       " 'growth_30d',\n",
       " 'growth_90d',\n",
       " 'growth_365d',\n",
       " 'growth_future_5d',\n",
       " 'SMA10',\n",
       " 'SMA20',\n",
       " 'growing_moving_average',\n",
       " 'high_minus_low_relative',\n",
       " 'volatility',\n",
       " 'is_positive_growth_5d_future',\n",
       " 'ticker_type',\n",
       " 'index_x',\n",
       " 'adx',\n",
       " 'adxr',\n",
       " 'apo',\n",
       " 'aroon_1',\n",
       " 'aroon_2',\n",
       " 'aroonosc',\n",
       " 'bop',\n",
       " 'cci',\n",
       " 'cmo',\n",
       " 'dx',\n",
       " 'macd',\n",
       " 'macdsignal',\n",
       " 'macdhist',\n",
       " 'macd_ext',\n",
       " 'macdsignal_ext',\n",
       " 'macdhist_ext',\n",
       " 'macd_fix',\n",
       " 'macdsignal_fix',\n",
       " 'macdhist_fix',\n",
       " 'mfi',\n",
       " 'minus_di',\n",
       " 'mom',\n",
       " 'plus_di',\n",
       " 'dm',\n",
       " 'ppo',\n",
       " 'roc',\n",
       " 'rocp',\n",
       " 'rocr',\n",
       " 'rocr100',\n",
       " 'rsi',\n",
       " 'slowk',\n",
       " 'slowd',\n",
       " 'fastk',\n",
       " 'fastd',\n",
       " 'fastk_rsi',\n",
       " 'fastd_rsi',\n",
       " 'trix',\n",
       " 'ultosc',\n",
       " 'willr',\n",
       " 'index_y',\n",
       " 'ad',\n",
       " 'adosc',\n",
       " 'obv',\n",
       " 'atr',\n",
       " 'natr',\n",
       " 'ht_dcperiod',\n",
       " 'ht_dcphase',\n",
       " 'ht_phasor_inphase',\n",
       " 'ht_phasor_quadrature',\n",
       " 'ht_sine_sine',\n",
       " 'ht_sine_leadsine',\n",
       " 'ht_trendmod',\n",
       " 'avgprice',\n",
       " 'medprice',\n",
       " 'typprice',\n",
       " 'wclprice',\n",
       " 'index',\n",
       " 'cdl2crows',\n",
       " 'cdl3blackrows',\n",
       " 'cdl3inside',\n",
       " 'cdl3linestrike',\n",
       " 'cdl3outside',\n",
       " 'cdl3starsinsouth',\n",
       " 'cdl3whitesoldiers',\n",
       " 'cdlabandonedbaby',\n",
       " 'cdladvancedblock',\n",
       " 'cdlbelthold',\n",
       " 'cdlbreakaway',\n",
       " 'cdlclosingmarubozu',\n",
       " 'cdlconcealbabyswall',\n",
       " 'cdlcounterattack',\n",
       " 'cdldarkcloudcover',\n",
       " 'cdldoji',\n",
       " 'cdldojistar',\n",
       " 'cdldragonflydoji',\n",
       " 'cdlengulfing',\n",
       " 'cdleveningdojistar',\n",
       " 'cdleveningstar',\n",
       " 'cdlgapsidesidewhite',\n",
       " 'cdlgravestonedoji',\n",
       " 'cdlhammer',\n",
       " 'cdlhangingman',\n",
       " 'cdlharami',\n",
       " 'cdlharamicross',\n",
       " 'cdlhighwave',\n",
       " 'cdlhikkake',\n",
       " 'cdlhikkakemod',\n",
       " 'cdlhomingpigeon',\n",
       " 'cdlidentical3crows',\n",
       " 'cdlinneck',\n",
       " 'cdlinvertedhammer',\n",
       " 'cdlkicking',\n",
       " 'cdlkickingbylength',\n",
       " 'cdlladderbottom',\n",
       " 'cdllongleggeddoji',\n",
       " 'cdllongline',\n",
       " 'cdlmarubozu',\n",
       " 'cdlmatchinglow',\n",
       " 'cdlmathold',\n",
       " 'cdlmorningdojistar',\n",
       " 'cdlmorningstar',\n",
       " 'cdlonneck',\n",
       " 'cdlpiercing',\n",
       " 'cdlrickshawman',\n",
       " 'cdlrisefall3methods',\n",
       " 'cdlseparatinglines',\n",
       " 'cdlshootingstar',\n",
       " 'cdlshortline',\n",
       " 'cdlspinningtop',\n",
       " 'cdlstalledpattern',\n",
       " 'cdlsticksandwich',\n",
       " 'cdltakuru',\n",
       " 'cdltasukigap',\n",
       " 'cdlthrusting',\n",
       " 'cdltristar',\n",
       " 'cdlunique3river',\n",
       " 'cdlupsidegap2crows',\n",
       " 'cdlxsidegap3methods',\n",
       " 'growth_dax_1d',\n",
       " 'growth_dax_3d',\n",
       " 'growth_dax_7d',\n",
       " 'growth_dax_30d',\n",
       " 'growth_dax_90d',\n",
       " 'growth_dax_365d',\n",
       " 'growth_snp500_1d',\n",
       " 'growth_snp500_3d',\n",
       " 'growth_snp500_7d',\n",
       " 'growth_snp500_30d',\n",
       " 'growth_snp500_90d',\n",
       " 'growth_snp500_365d',\n",
       " 'growth_dji_1d',\n",
       " 'growth_dji_3d',\n",
       " 'growth_dji_7d',\n",
       " 'growth_dji_30d',\n",
       " 'growth_dji_90d',\n",
       " 'growth_dji_365d',\n",
       " 'growth_epi_1d',\n",
       " 'growth_epi_3d',\n",
       " 'growth_epi_7d',\n",
       " 'growth_epi_30d',\n",
       " 'growth_epi_90d',\n",
       " 'growth_epi_365d',\n",
       " 'Quarter',\n",
       " 'gdppot_us_yoy',\n",
       " 'gdppot_us_qoq',\n",
       " 'cpi_core_yoy',\n",
       " 'cpi_core_mom',\n",
       " 'FEDFUNDS',\n",
       " 'DGS1',\n",
       " 'DGS5',\n",
       " 'DGS10',\n",
       " 'Adj Close_y',\n",
       " 'growth_gold_1d',\n",
       " 'growth_gold_3d',\n",
       " 'growth_gold_7d',\n",
       " 'growth_gold_30d',\n",
       " 'growth_gold_90d',\n",
       " 'growth_gold_365d',\n",
       " 'growth_wti_oil_1d',\n",
       " 'growth_wti_oil_3d',\n",
       " 'growth_wti_oil_7d',\n",
       " 'growth_wti_oil_30d',\n",
       " 'growth_wti_oil_90d',\n",
       " 'growth_wti_oil_365d',\n",
       " 'growth_brent_oil_1d',\n",
       " 'growth_brent_oil_3d',\n",
       " 'growth_brent_oil_7d',\n",
       " 'growth_brent_oil_30d',\n",
       " 'growth_brent_oil_90d',\n",
       " 'growth_brent_oil_365d',\n",
       " 'growth_btc_usd_1d',\n",
       " 'growth_btc_usd_3d',\n",
       " 'growth_btc_usd_7d',\n",
       " 'growth_btc_usd_30d',\n",
       " 'growth_btc_usd_90d',\n",
       " 'growth_btc_usd_365d']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(full_df_colab.columns)"
   ]
  },
  {
   "cell_type": "code",
=======
=======
>>>>>>> 9df35aa (Trying to solve question 4 but not yet)
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 221109 entries, 0 to 5425\n",
      "Columns: 202 entries, Open to growth_btc_usd_365d\n",
      "dtypes: datetime64[ns](3), float64(128), int32(66), int64(3), object(2)\n",
      "memory usage: 286.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-13</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-14</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-17</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-18</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1986-03-19</td>\n",
       "      <td>1986-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month       Date    Quarter\n",
       "0    1986-03-01 1986-03-13 1986-01-01\n",
       "1    1986-03-01 1986-03-14 1986-01-01\n",
       "2    1986-03-01 1986-03-17 1986-01-01\n",
       "3    1986-03-01 1986-03-18 1986-01-01\n",
       "4    1986-03-01 1986-03-19 1986-01-01\n",
       "...         ...        ...        ...\n",
       "5421 2024-04-01 2024-04-29 2024-04-01\n",
       "5422 2024-04-01 2024-04-30 2024-04-01\n",
       "5423 2024-05-01 2024-05-02 2024-04-01\n",
       "5424 2024-05-01 2024-05-03 2024-04-01\n",
       "5425 2024-05-01 2024-05-06 2024-04-01\n",
       "\n",
       "[221109 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.select_dtypes(include='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['TP'] = (full_df['High'] + full_df['Low'] + full_df['Close']) / 3\n",
    "full_df['SMA'] = full_df['TP'].rolling(window=20).mean()\n",
    "full_df['CCI'] = (full_df['TP'] - full_df['SMA']) / ( 0.015 * full_df['TP'].rolling(window=20).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "      <th>TP</th>\n",
       "      <th>SMA</th>\n",
       "      <th>CCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>3606.100098</td>\n",
       "      <td>3649.899902</td>\n",
       "      <td>3605.199951</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>3634.300049</td>\n",
       "      <td>1.396979e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>1.011533</td>\n",
       "      <td>1.001346</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.916661</td>\n",
       "      <td>1.486315</td>\n",
       "      <td>2.181200</td>\n",
       "      <td>3629.799967</td>\n",
       "      <td>3688.120833</td>\n",
       "      <td>-39.282699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1.571996e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.850046</td>\n",
       "      <td>1.423982</td>\n",
       "      <td>2.158543</td>\n",
       "      <td>3609.100016</td>\n",
       "      <td>3680.662500</td>\n",
       "      <td>-48.174406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3.748847e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931945</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.926103</td>\n",
       "      <td>0.916902</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>1.369046</td>\n",
       "      <td>2.038296</td>\n",
       "      <td>3603.233317</td>\n",
       "      <td>3669.645829</td>\n",
       "      <td>-46.877716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4.079696e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946816</td>\n",
       "      <td>1.063704</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>1.462818</td>\n",
       "      <td>2.180063</td>\n",
       "      <td>3536.750000</td>\n",
       "      <td>3655.839164</td>\n",
       "      <td>-85.763917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2.614667e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3477.133382</td>\n",
       "      <td>3640.490837</td>\n",
       "      <td>-113.935329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221109 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "0        0.088542     0.101563     0.088542     0.097222     0.060163   \n",
       "1        0.097222     0.102431     0.097222     0.100694     0.062311   \n",
       "2        0.100694     0.103299     0.100694     0.102431     0.063386   \n",
       "3        0.102431     0.103299     0.098958     0.099826     0.061774   \n",
       "4        0.099826     0.100694     0.097222     0.098090     0.060700   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5421  3606.100098  3649.899902  3605.199951  3634.300049  3634.300049   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "\n",
       "            Volume Ticker  Year      Month  Weekday  ...  \\\n",
       "0     1.031789e+09   MSFT  1986 1986-03-01        3  ...   \n",
       "1     3.081600e+08   MSFT  1986 1986-03-01        4  ...   \n",
       "2     1.331712e+08   MSFT  1986 1986-03-01        0  ...   \n",
       "3     6.776640e+07   MSFT  1986 1986-03-01        1  ...   \n",
       "4     4.789440e+07   MSFT  1986 1986-03-01        2  ...   \n",
       "...            ...    ...   ...        ...      ...  ...   \n",
       "5421  1.396979e+06  LT.NS  2024 2024-04-01        0  ...   \n",
       "5422  1.571996e+06  LT.NS  2024 2024-04-01        1  ...   \n",
       "5423  3.748847e+06  LT.NS  2024 2024-05-01        3  ...   \n",
       "5424  4.079696e+06  LT.NS  2024 2024-05-01        4  ...   \n",
       "5425  2.614667e+06  LT.NS  2024 2024-05-01        0  ...   \n",
       "\n",
       "     growth_brent_oil_365d  growth_btc_usd_1d  growth_btc_usd_3d  \\\n",
       "0                      NaN                NaN                NaN   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                      NaN                NaN                NaN   \n",
       "3                      NaN                NaN                NaN   \n",
       "4                      NaN                NaN                NaN   \n",
       "...                    ...                ...                ...   \n",
       "5421              0.949109           1.011533           1.001346   \n",
       "5422              0.936075           0.949809           0.956129   \n",
       "5423              0.931945           1.014925           0.926103   \n",
       "5424              0.946816           1.063704           1.037155   \n",
       "5425              0.954603                NaN                NaN   \n",
       "\n",
       "      growth_btc_usd_7d  growth_btc_usd_30d  growth_btc_usd_90d  \\\n",
       "0                   NaN                 NaN                 NaN   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "2                   NaN                 NaN                 NaN   \n",
       "3                   NaN                 NaN                 NaN   \n",
       "4                   NaN                 NaN                 NaN   \n",
       "...                 ...                 ...                 ...   \n",
       "5421           0.955167            0.916661            1.486315   \n",
       "5422           0.913106            0.850046            1.423982   \n",
       "5423           0.916902            0.903379            1.369046   \n",
       "5424           0.986425            0.953153            1.462818   \n",
       "5425                NaN                 NaN                 NaN   \n",
       "\n",
       "      growth_btc_usd_365d           TP          SMA         CCI  \n",
       "0                     NaN     0.095776          NaN         NaN  \n",
       "1                     NaN     0.100116          NaN         NaN  \n",
       "2                     NaN     0.102141          NaN         NaN  \n",
       "3                     NaN     0.100694          NaN         NaN  \n",
       "4                     NaN     0.098669          NaN         NaN  \n",
       "...                   ...          ...          ...         ...  \n",
       "5421             2.181200  3629.799967  3688.120833  -39.282699  \n",
       "5422             2.158543  3609.100016  3680.662500  -48.174406  \n",
       "5423             2.038296  3603.233317  3669.645829  -46.877716  \n",
       "5424             2.180063  3536.750000  3655.839164  -85.763917  \n",
       "5425                  NaN  3477.133382  3640.490837 -113.935329  \n",
       "\n",
       "[221109 rows x 205 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close_x', 'Volume', 'Ticker',\n",
       "       'Year', 'Month', 'Weekday',\n",
       "       ...\n",
       "       'growth_brent_oil_365d', 'growth_btc_usd_1d', 'growth_btc_usd_3d',\n",
       "       'growth_btc_usd_7d', 'growth_btc_usd_30d', 'growth_btc_usd_90d',\n",
       "       'growth_btc_usd_365d', 'TP', 'SMA', 'CCI'],\n",
       "      dtype='object', length=205)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_trades = full_df[(full_df['Date'].dt.dayofweek == 4) & (full_df['CCI'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>40.450001</td>\n",
       "      <td>40.970001</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>40.939999</td>\n",
       "      <td>34.912762</td>\n",
       "      <td>34567600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997447</td>\n",
       "      <td>1.005607</td>\n",
       "      <td>1.021664</td>\n",
       "      <td>0.995813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>45.110001</td>\n",
       "      <td>45.910000</td>\n",
       "      <td>39.395618</td>\n",
       "      <td>36939400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983610</td>\n",
       "      <td>0.941627</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>45.660000</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>41.630741</td>\n",
       "      <td>130933700.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1.143658</td>\n",
       "      <td>1.055457</td>\n",
       "      <td>0.614516</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>1.037625</td>\n",
       "      <td>0.939362</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>44.270000</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>40.151123</td>\n",
       "      <td>41839000.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007958</td>\n",
       "      <td>1.032390</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>1.002560</td>\n",
       "      <td>1.009139</td>\n",
       "      <td>1.034930</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.632660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>52.299999</td>\n",
       "      <td>54.070000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>46.583046</td>\n",
       "      <td>135227100.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976399</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.751370</td>\n",
       "      <td>0.435520</td>\n",
       "      <td>1.009025</td>\n",
       "      <td>1.026100</td>\n",
       "      <td>1.051840</td>\n",
       "      <td>1.200679</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.771437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>2061.000000</td>\n",
       "      <td>2095.800049</td>\n",
       "      <td>2058.449951</td>\n",
       "      <td>2062.750000</td>\n",
       "      <td>2058.108887</td>\n",
       "      <td>2652761.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891008</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>1.124210</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.020511</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.795450</td>\n",
       "      <td>0.824372</td>\n",
       "      <td>0.288467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2483.500000</td>\n",
       "      <td>2415.050049</td>\n",
       "      <td>2475.550049</td>\n",
       "      <td>2469.979980</td>\n",
       "      <td>2690699.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971214</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.901866</td>\n",
       "      <td>0.870323</td>\n",
       "      <td>1.001048</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>1.119678</td>\n",
       "      <td>1.072726</td>\n",
       "      <td>1.540443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2521.100098</td>\n",
       "      <td>2586.250000</td>\n",
       "      <td>2580.430908</td>\n",
       "      <td>4610417.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011984</td>\n",
       "      <td>1.053541</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>0.869197</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>1.075177</td>\n",
       "      <td>1.291138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2928.699951</td>\n",
       "      <td>2872.449951</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>2901.600098</td>\n",
       "      <td>3638510.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060358</td>\n",
       "      <td>1.076092</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.751347</td>\n",
       "      <td>0.987251</td>\n",
       "      <td>1.004875</td>\n",
       "      <td>1.004067</td>\n",
       "      <td>0.876331</td>\n",
       "      <td>1.002105</td>\n",
       "      <td>1.340190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>3129.949951</td>\n",
       "      <td>3197.949951</td>\n",
       "      <td>3121.050049</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>3190.649902</td>\n",
       "      <td>2112908.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962421</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.936372</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>1.025880</td>\n",
       "      <td>1.022671</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>1.091754</td>\n",
       "      <td>1.495576</td>\n",
       "      <td>2.280217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "7113    40.450001    40.970001    40.250000    40.939999    34.912762   \n",
       "7181    45.110001    45.930000    45.110001    45.910000    39.395618   \n",
       "7340    45.660000    48.139999    45.650002    47.869999    41.630741   \n",
       "7452    44.270000    45.570000    43.919998    45.570000    40.151123   \n",
       "7467    52.299999    54.070000    52.250000    52.869999    46.583046   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5072  2061.000000  2095.800049  2058.449951  2062.750000  2058.108887   \n",
       "5219  2420.000000  2483.500000  2415.050049  2475.550049  2469.979980   \n",
       "5234  2522.000000  2595.000000  2521.100098  2586.250000  2580.430908   \n",
       "5268  2888.000000  2928.699951  2872.449951  2901.600098  2901.600098   \n",
       "5323  3129.949951  3197.949951  3121.050049  3190.649902  3190.649902   \n",
       "\n",
       "           Volume Ticker  Year      Month  Weekday  ... growth_brent_oil_7d  \\\n",
       "7113   34567600.0   MSFT  2014 2014-05-01        4  ...            0.997447   \n",
       "7181   36939400.0   MSFT  2014 2014-09-01        4  ...            0.983610   \n",
       "7340  130933700.0   MSFT  2015 2015-04-01        4  ...            1.082228   \n",
       "7452   41839000.0   MSFT  2015 2015-10-01        4  ...            1.007958   \n",
       "7467  135227100.0   MSFT  2015 2015-10-01        4  ...            0.976399   \n",
       "...           ...    ...   ...        ...      ...  ...                 ...   \n",
       "5072    2652761.0  LT.NS  2022 2022-11-01        4  ...            0.891008   \n",
       "5219    2690699.0  LT.NS  2023 2023-06-01        4  ...            0.971214   \n",
       "5234    4610417.0  LT.NS  2023 2023-07-01        4  ...            1.011984   \n",
       "5268    3638510.0  LT.NS  2023 2023-09-01        4  ...            1.060358   \n",
       "5323    2112908.0  LT.NS  2023 2023-12-01        4  ...            0.962421   \n",
       "\n",
       "      growth_brent_oil_30d  growth_brent_oil_90d  growth_brent_oil_365d  \\\n",
       "7113              1.005607              1.021664               0.995813   \n",
       "7181              0.941627              0.925124               0.914716   \n",
       "7340              1.143658              1.055457               0.614516   \n",
       "7452              1.032390              0.775540               0.441114   \n",
       "7467              0.996884              0.751370               0.435520   \n",
       "...                    ...                   ...                    ...   \n",
       "5072              0.884318              0.782174               1.124210   \n",
       "5219              0.973233              0.901866               0.870323   \n",
       "5234              1.053541              1.003714               0.869197   \n",
       "5268              1.076092              1.142983               0.751347   \n",
       "5323              0.855903              0.936372               0.705924   \n",
       "\n",
       "      growth_btc_usd_1d  growth_btc_usd_3d  growth_btc_usd_7d  \\\n",
       "7113                NaN                NaN                NaN   \n",
       "7181                NaN                NaN                NaN   \n",
       "7340           0.978035           0.982994           1.037625   \n",
       "7452           0.998922           1.002560           1.009139   \n",
       "7467           1.009025           1.026100           1.051840   \n",
       "...                 ...                ...                ...   \n",
       "5072           0.995024           1.020511           0.989464   \n",
       "5219           1.001048           0.993127           0.992891   \n",
       "5234           1.003918           1.001748           0.985979   \n",
       "5268           0.987251           1.004875           1.004067   \n",
       "5323           1.025880           1.022671           1.025675   \n",
       "\n",
       "      growth_btc_usd_30d  growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "7113                 NaN                 NaN                  NaN  \n",
       "7181                 NaN                 NaN                  NaN  \n",
       "7340            0.939362            0.933108                  NaN  \n",
       "7452            1.034930            0.909566             0.632660  \n",
       "7467            1.200679            0.957738             0.771437  \n",
       "...                  ...                 ...                  ...  \n",
       "5072            0.795450            0.824372             0.288467  \n",
       "5219            1.119678            1.072726             1.540443  \n",
       "5234            0.996052            1.075177             1.291138  \n",
       "5268            0.876331            1.002105             1.340190  \n",
       "5323            1.091754            1.495576             2.280217  \n",
       "\n",
       "[460 rows x 202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades_colab = full_df_colab[(full_df_colab['Date'].dt.dayofweek == 4) & (full_df_colab['cci']>200)]\n",
    "qualifying_trades_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-04-27 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifying_trades.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1986-04-30 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[30]['Date'] + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected gross profit (in thousands of dollars): -7\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to store gross profit\n",
    "gross_profit = 0\n",
    "\n",
    "# Iterate through each qualifying trade\n",
    "for index,row in qualifying_trades.iterrows():\n",
    "    # Calculate the buy price (Adj. Close price)\n",
    "    buy_price = row['Adj Close_x']\n",
    "    #print(buy_price, 'buy')\n",
    "    # Try to find the sell price after 5 trading days\n",
    "    try:\n",
    "        sell_price = full_df_colab.loc[(full_df_colab['Date']==full_df_colab.iloc[index]['Date'] + pd.Timedelta(days=5))  & (full_df_colab['Ticker']==row['Ticker'])]['growth_future_5d'].iloc[0]\n",
    "        #print(sell_price, 'sell')\n",
    "    except KeyError and IndexError:\n",
    "        # If there are not enough trading days in the future, skip this trade\n",
    "        continue\n",
    "    \n",
    "    # Calculate the profit or loss from this trade\n",
    "    trade_profit = (sell_price - buy_price) * (1000 / buy_price)\n",
    "    #print(trade_profit, 'profit')\n",
    "    gross_profit += trade_profit\n",
    "\n",
    "# Convert the gross profit to thousands of dollars and round to the nearest integer\n",
    "gross_profit_thousands = round(gross_profit/1000)\n",
    "\n",
    "# Display the expected gross profit\n",
    "print(\"Expected gross profit (in thousands of dollars):\", gross_profit_thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EXPLORATORY] Question 5: Finding Your Strategy for IPOs\n",
    "\n",
    "You've seen in the first questions that the median and average investments are negative in IPOs, and you can't blindly invest in all deals.\n",
    "\n",
    "How would you correct/refine the approach? Briefly describe the steps and the data you'll try to get (it should be generally feasible to do it from public sources - no access to internal data of companies)?\n",
    "\n",
    "E.g. (some ideas) Do you want to focus on the specific vertical? Do you want to build a smart comparison vs. existing stocks on the market? Or you just will want to get some features (which features?) like total number of people in a company to find a segment of \"successful\" IPOs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, I would try to make the scope smaller. Look for growth and performance in several industries. Other step would be probably to read news about how is the market demand and the sentiment in general for those IPO. Finally, is not a bad idea on check for experts opinions. \n",
    "I think the best way to analyse an IPO is to make a smart comparison against existing stocks. "
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
>>>>>>> 02abad3 (Done with the questions for the homework2)
=======
>>>>>>> 2269700 (previous changes hw2)
<<<<<<< HEAD
=======
=======
>>>>>>> d9aadfaaebb9f6dc901affb5597ef327997d0c86
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "undefined.undefined.undefined"
=======
   "version": "3.10.14"
>>>>>>> c20d40f (Add response to first question)
=======
   "version": "3.10.14"
>>>>>>> a1fa175 (Add response to first question)
=======
   "version": "undefined.undefined.undefined"
>>>>>>> 2269700 (previous changes hw2)
=======
   "version": "undefined.undefined.undefined"
>>>>>>> 793fda001b04ba2fb91e5870b4393b7262adc4c8
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
